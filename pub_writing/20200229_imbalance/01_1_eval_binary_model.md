
# 二値分類モデルの評価

ここでは二値分類モデルを、あるデータ点について正の例である確率を返す関数であると仮定する。そうしたモデルを用いて二値分類を行う場合、正負の予測は関数の出力を閾値で分けることで実現できる。閾値を決めることで各データ点が混合行列のどこに入るかが決まり、PrecisionやRecallなどの指標を用いて二値分類の評価ができる。つまり閾値次第で分類の結果が変わるので、閾値に依存しない形でモデルの評価を行いたい。

そういったときによく用いられるのがROC曲線やPR曲線、そしてそれらをそれぞれ一つの数字に落とし込んだものがAUCやAPである。

## モデル性能

そもそも良いモデル、悪いモデルというのはどういうものなのだろうか。

- 良いモデル：完全モデル。スコアがそのまま予測確率になっているモデルである。つまり、同等なスコアの集団を集めてきた場合、正例の数がスコアをそのまま母数ｐとする二項分布に従うというモデルである。この場合、スコアとスコアで層別化した正例率をプロットすると直線に乗り、相関係数は１になる。

- 悪いモデル：ポンコツモデル。正解ラベルがなんであっても二値分類スコアとして０－１の一様乱数を出力するモデルである。前述のスコアと層別化正例率の相関が無いというものである。

- 現実的なモデル：現実にはスコアと層別化正例率は概ね相関があるものの直線に乗ることは少ない。



忙しい人はAUCが0.8くらいで良いモデル、0.9だと過学習なんじゃないのと判断してしまうことがよくあるが、結局自分の考えている領域内の比較で良し悪しを判断すべきである。ビッグで不均衡なデータだと多様性により学習が困難となり、AUCが0.7に満たないモデルで運用していることもある。

AUC、APは順序性しか見ていないため、何らかのシステムでスコア値を下流で処理に用いる場合には注意が必要がある。例えば、二つのモデルのスコアを比較して高いほうを採用するといった文脈付きバンディット問題を考える場合にはスコアの絶対値が比較可能かを検証しておくべきである。

スコアの絶対値を直接評価する場合はLoglossを使う。数式的には、、

#### ROC曲線
Receiver Operatorating Characteristic curve（受信者動作特性曲線)
左のほうは閾値が厳しい、右に行くと緩くなる。下記のAUCが同じなら左のほうの立ち上がりが良いほうが良いモデルである。なぜならその場合、FPRをあまり上げずにTPRを上げることができているからである。
ROC曲線では正負の割合がわからない。
正負ともに分類の数を元に議論をする場合には便利である。例えば、ある病気の検査で偽陽性、つまり本当は病気ではないのに病気であると判断されることに何らかの損失が考えられる場合、偽陽性の数の増減により全体の損失がどのように変動するかを議論できる。

- AUC
ROCの下側面積Area Under Curve。

#### Recall-Precision曲線
不均衡データだと左のほうでギザギザする。右に行くと閾値を緩くすることになるのでPrecisionは下がる。
RP曲線は不均衡データが一目瞭然
正の言い当てを重視する場合にはROCよりも便利である。例えば、真に正を半分集める（Recallが0.5）ためには30％の言い当て率（Precisionが0.3）で我慢しなくてはならないといった具合である。この際、負例には興味がなく、スコアの最大値をとるようなバンディット問題では有用だと言える。

### AP
Recall-Precision curveの下側面積であり、スコアの閾値を色々変えたときのPrecision

### logloss

### スコア絶対値
スコアの順序の評価
