{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from srgan import SRGAN\n",
    "from generator import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data/train/low/'\n",
    "tgt_dir = 'data/train/high/'\n",
    "\n",
    "test_file = 'UBMk30rjy0o_17675_1.jpg'\n",
    "test_low_path =  'data/val/low/' + test_file\n",
    "test_high_path = 'data/val/high/' + test_file\n",
    "test_out_path = 'data/out/' + test_file\n",
    "test_test_path = 'data/test/' + test_file\n",
    "\n",
    "vgg_path = 'vgg16_notop.hdf5'\n",
    "\n",
    "input_shape = (135, 240, 3)\n",
    "tgt_shape = (540, 960, 3)\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "srgan = SRGAN(vgg_path, batch_size, input_shape, tgt_shape)\n",
    "gen = ImageDataGenerator(input_dir, tgt_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_low = ((cv2.imread(test_low_path) - 127.5) / 127.5)[np.newaxis, :, :, :]\n",
    "test_img_high = ((cv2.imread(test_high_path)- 127.5) / 127.5)[np.newaxis, :, :, :]\n",
    "\n",
    "test_img_sr = srgan.generator.predict(test_img_low)\n",
    "test_img_sr_int = ((test_img_sr * 127.5) + 127.5).astype('u1')[0]\n",
    "cv2.imwrite(test_test_path, test_img_sr_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[4,540,960,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node SquaredDifference_27-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_19056]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fe2063f94d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msrgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_high\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/keras/srgan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_low, X_high)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[4,540,960,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node SquaredDifference_27-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_19056]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "for e in range(5):\n",
    "    print('epoch', e)\n",
    "    X_low, X_high = gen.flow_from_directory().__next__()\n",
    "    srgan.train(X_low, X_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "d_loss 0.6181113719940186\n",
      "epoch 1\n",
      "d_loss 0.623425304889679\n",
      "epoch 2\n",
      "d_loss 0.6893672347068787\n",
      "epoch 3\n",
      "d_loss 0.6618378162384033\n",
      "epoch 4\n",
      "d_loss 0.674908459186554\n",
      "epoch 5\n",
      "d_loss 0.6163884401321411\n",
      "epoch 6\n",
      "d_loss 0.6246289014816284\n",
      "epoch 7\n",
      "d_loss 0.7069726586341858\n",
      "epoch 8\n",
      "d_loss 0.6114041805267334\n",
      "epoch 9\n",
      "d_loss 0.6736556887626648\n",
      "epoch 10\n",
      "d_loss 0.6871210336685181\n",
      "epoch 11\n",
      "d_loss 0.6945561170578003\n",
      "epoch 12\n",
      "d_loss 0.6211631894111633\n",
      "epoch 13\n",
      "d_loss 0.662213921546936\n",
      "epoch 14\n",
      "d_loss 0.6196154952049255\n",
      "epoch 15\n",
      "d_loss 0.6379116773605347\n",
      "epoch 16\n",
      "d_loss 0.7054023146629333\n",
      "epoch 17\n",
      "d_loss 0.674554169178009\n",
      "epoch 18\n",
      "d_loss 0.7110623717308044\n",
      "epoch 19\n",
      "d_loss 0.6532878279685974\n",
      "epoch 20\n",
      "d_loss 0.6886740922927856\n",
      "epoch 21\n",
      "d_loss 0.7100696563720703\n",
      "epoch 22\n",
      "d_loss 0.6412782669067383\n",
      "epoch 23\n",
      "d_loss 0.6445339918136597\n",
      "epoch 24\n",
      "d_loss 0.6390447616577148\n",
      "epoch 25\n",
      "d_loss 0.6458838582038879\n",
      "epoch 26\n",
      "d_loss 0.6263339519500732\n",
      "epoch 27\n",
      "d_loss 0.7179872393608093\n",
      "epoch 28\n",
      "d_loss 0.5916368365287781\n",
      "epoch 29\n",
      "d_loss 0.610282301902771\n",
      "epoch 30\n",
      "d_loss 0.6898995637893677\n",
      "epoch 31\n",
      "d_loss 0.7204813957214355\n",
      "epoch 32\n",
      "d_loss 0.6873847842216492\n",
      "epoch 33\n",
      "d_loss 0.7199933528900146\n",
      "epoch 34\n",
      "d_loss 0.6292038559913635\n",
      "epoch 35\n",
      "d_loss 0.7066662311553955\n",
      "epoch 36\n",
      "d_loss 0.6193709373474121\n",
      "epoch 37\n",
      "d_loss 0.6195626258850098\n",
      "epoch 38\n",
      "d_loss 0.601617157459259\n",
      "epoch 39\n",
      "d_loss 0.6380985975265503\n",
      "epoch 40\n",
      "d_loss 0.6256786584854126\n",
      "epoch 41\n",
      "d_loss 0.6498585939407349\n",
      "epoch 42\n",
      "d_loss 0.766930103302002\n",
      "epoch 43\n",
      "d_loss 0.7135952711105347\n",
      "epoch 44\n",
      "d_loss 0.6930275559425354\n",
      "epoch 45\n",
      "d_loss 0.6484240293502808\n",
      "epoch 46\n",
      "d_loss 0.7013051509857178\n",
      "epoch 47\n",
      "d_loss 0.6568964123725891\n",
      "epoch 48\n",
      "d_loss 0.7082374691963196\n",
      "epoch 49\n",
      "d_loss 0.5872113704681396\n",
      "epoch 50\n",
      "d_loss 0.6510440111160278\n",
      "epoch 51\n",
      "d_loss 0.6078921556472778\n",
      "epoch 52\n",
      "d_loss 0.7311347723007202\n",
      "epoch 53\n",
      "d_loss 0.5799340009689331\n",
      "epoch 54\n",
      "d_loss 0.5933966636657715\n",
      "epoch 55\n",
      "d_loss 0.5923330783843994\n",
      "epoch 56\n",
      "d_loss 0.5779927968978882\n",
      "epoch 57\n",
      "d_loss 0.6007944345474243\n",
      "epoch 58\n",
      "d_loss 0.606102466583252\n",
      "epoch 59\n",
      "d_loss 0.5815653204917908\n",
      "epoch 60\n",
      "d_loss 0.5883071422576904\n",
      "epoch 61\n",
      "d_loss 0.7089458703994751\n",
      "epoch 62\n",
      "d_loss 0.5858314037322998\n",
      "epoch 63\n",
      "d_loss 0.7514760494232178\n",
      "epoch 64\n",
      "d_loss 0.597632646560669\n",
      "epoch 65\n",
      "d_loss 0.5716325640678406\n",
      "epoch 66\n",
      "d_loss 0.5661277770996094\n",
      "epoch 67\n",
      "d_loss 0.632534921169281\n",
      "epoch 68\n",
      "d_loss 0.5793140530586243\n",
      "epoch 69\n",
      "d_loss 0.702132523059845\n",
      "epoch 70\n",
      "d_loss 0.607373833656311\n",
      "epoch 71\n",
      "d_loss 0.5616833567619324\n",
      "epoch 72\n",
      "d_loss 0.5630480051040649\n",
      "epoch 73\n",
      "d_loss 0.6750974059104919\n",
      "epoch 74\n",
      "d_loss 0.5852504372596741\n",
      "epoch 75\n",
      "d_loss 0.6641578674316406\n",
      "epoch 76\n",
      "d_loss 0.658142626285553\n",
      "epoch 77\n",
      "d_loss 0.6607920527458191\n",
      "epoch 78\n",
      "d_loss 0.5870320796966553\n",
      "epoch 79\n",
      "d_loss 0.5530378818511963\n",
      "epoch 80\n",
      "d_loss 0.6038085222244263\n",
      "epoch 81\n",
      "d_loss 0.560236930847168\n",
      "epoch 82\n",
      "d_loss 0.5614138841629028\n",
      "epoch 83\n",
      "d_loss 0.715370774269104\n",
      "epoch 84\n",
      "d_loss 0.5896593332290649\n",
      "epoch 85\n",
      "d_loss 0.6823598146438599\n",
      "epoch 86\n",
      "d_loss 0.5941212177276611\n",
      "epoch 87\n",
      "d_loss 0.7017873525619507\n",
      "epoch 88\n",
      "d_loss 0.5615628957748413\n",
      "epoch 89\n",
      "d_loss 0.6025680303573608\n",
      "epoch 90\n",
      "d_loss 0.581116795539856\n",
      "epoch 91\n",
      "d_loss 0.5717013478279114\n",
      "epoch 92\n",
      "d_loss 0.5522211790084839\n",
      "epoch 93\n",
      "d_loss 0.6593171954154968\n",
      "epoch 94\n",
      "d_loss 0.5701347589492798\n",
      "epoch 95\n",
      "d_loss 0.632480800151825\n",
      "epoch 96\n",
      "d_loss 0.5633093118667603\n",
      "epoch 97\n",
      "d_loss 0.7317804098129272\n",
      "epoch 98\n",
      "d_loss 0.5634932518005371\n",
      "epoch 99\n",
      "d_loss 0.5620110034942627\n",
      "epoch 100\n",
      "d_loss 0.5522837042808533\n",
      "epoch 101\n",
      "d_loss 0.5512557029724121\n",
      "epoch 102\n",
      "d_loss 0.5450872182846069\n",
      "epoch 103\n",
      "d_loss 0.6140164136886597\n",
      "epoch 104\n",
      "d_loss 0.5870481729507446\n",
      "epoch 105\n",
      "d_loss 0.5776506662368774\n",
      "epoch 106\n",
      "d_loss 0.7081496119499207\n",
      "epoch 107\n",
      "d_loss 0.5997345447540283\n",
      "epoch 108\n",
      "d_loss 0.5324505567550659\n",
      "epoch 109\n",
      "d_loss 0.5588526725769043\n",
      "epoch 110\n",
      "d_loss 0.7122013568878174\n",
      "epoch 111\n",
      "d_loss 0.5455464124679565\n",
      "epoch 112\n",
      "d_loss 0.6333919763565063\n",
      "epoch 113\n",
      "d_loss 0.7415398359298706\n",
      "epoch 114\n",
      "d_loss 0.5325036644935608\n",
      "epoch 115\n",
      "d_loss 0.6057804226875305\n",
      "epoch 116\n",
      "d_loss 0.5296187996864319\n",
      "epoch 117\n",
      "d_loss 0.5418980121612549\n",
      "epoch 118\n",
      "d_loss 0.5344157218933105\n",
      "epoch 119\n",
      "d_loss 0.5346514582633972\n",
      "epoch 120\n",
      "d_loss 0.585342526435852\n",
      "epoch 121\n",
      "d_loss 0.5318711996078491\n",
      "epoch 122\n",
      "d_loss 0.5327739119529724\n",
      "epoch 123\n",
      "d_loss 0.5706276893615723\n",
      "epoch 124\n",
      "d_loss 0.5470609664916992\n",
      "epoch 125\n",
      "d_loss 0.5174208879470825\n",
      "epoch 126\n",
      "d_loss 0.5247524976730347\n",
      "epoch 127\n",
      "d_loss 0.5640389919281006\n",
      "epoch 128\n",
      "d_loss 0.6528865694999695\n",
      "epoch 129\n",
      "d_loss 0.5663127899169922\n",
      "epoch 130\n",
      "d_loss 0.5801176428794861\n",
      "epoch 131\n",
      "d_loss 0.6950162053108215\n",
      "epoch 132\n",
      "d_loss 0.5182086825370789\n",
      "epoch 133\n",
      "d_loss 0.5386348962783813\n",
      "epoch 134\n",
      "d_loss 0.5027748942375183\n",
      "epoch 135\n",
      "d_loss 0.5205928087234497\n",
      "epoch 136\n",
      "d_loss 0.5130505561828613\n",
      "epoch 137\n",
      "d_loss 0.5059309601783752\n",
      "epoch 138\n",
      "d_loss 0.5393004417419434\n",
      "epoch 139\n",
      "d_loss 0.5334182977676392\n",
      "epoch 140\n",
      "d_loss 0.5172012448310852\n",
      "epoch 141\n",
      "d_loss 0.5012094974517822\n",
      "epoch 142\n",
      "d_loss 0.5156935453414917\n",
      "epoch 143\n",
      "d_loss 0.6350979804992676\n",
      "epoch 144\n",
      "d_loss 0.5569261312484741\n",
      "epoch 145\n",
      "d_loss 0.5015775561332703\n",
      "epoch 146\n",
      "d_loss 0.4962853789329529\n",
      "epoch 147\n",
      "d_loss 0.49142560362815857\n",
      "epoch 148\n",
      "d_loss 0.7802351713180542\n",
      "epoch 149\n",
      "d_loss 0.5199776887893677\n",
      "epoch 150\n",
      "d_loss 0.6293227672576904\n",
      "epoch 151\n",
      "d_loss 0.5061151385307312\n",
      "epoch 152\n",
      "d_loss 0.5044407248497009\n",
      "epoch 153\n",
      "d_loss 0.5156526565551758\n",
      "epoch 154\n",
      "d_loss 0.8008120059967041\n",
      "epoch 155\n",
      "d_loss 0.4951521158218384\n",
      "epoch 156\n",
      "d_loss 0.5178213715553284\n",
      "epoch 157\n",
      "d_loss 0.5217709541320801\n",
      "epoch 158\n",
      "d_loss 0.5507102012634277\n",
      "epoch 159\n",
      "d_loss 0.4818936884403229\n",
      "epoch 160\n",
      "d_loss 0.5471878051757812\n",
      "epoch 161\n",
      "d_loss 0.4924505054950714\n",
      "epoch 162\n",
      "d_loss 0.4848436117172241\n",
      "epoch 163\n",
      "d_loss 0.562009334564209\n",
      "epoch 164\n",
      "d_loss 0.48725682497024536\n",
      "epoch 165\n",
      "d_loss 0.4740701913833618\n",
      "epoch 166\n",
      "d_loss 0.5582941770553589\n",
      "epoch 167\n",
      "d_loss 0.49000784754753113\n",
      "epoch 168\n",
      "d_loss 0.4866825342178345\n",
      "epoch 169\n",
      "d_loss 0.4677794873714447\n",
      "epoch 170\n",
      "d_loss 0.47656506299972534\n",
      "epoch 171\n",
      "d_loss 0.49880537390708923\n",
      "epoch 172\n",
      "d_loss 0.7016956806182861\n",
      "epoch 173\n",
      "d_loss 0.5620932579040527\n",
      "epoch 174\n",
      "d_loss 0.48609939217567444\n",
      "epoch 175\n",
      "d_loss 0.5789520740509033\n",
      "epoch 176\n",
      "d_loss 0.5314925909042358\n",
      "epoch 177\n",
      "d_loss 0.4641745984554291\n",
      "epoch 178\n",
      "d_loss 0.4701329171657562\n",
      "epoch 179\n",
      "d_loss 0.4639587998390198\n",
      "epoch 180\n",
      "d_loss 0.7402545213699341\n",
      "epoch 181\n",
      "d_loss 0.7536817193031311\n",
      "epoch 182\n",
      "d_loss 0.4480973780155182\n",
      "epoch 183\n",
      "d_loss 0.692870020866394\n",
      "epoch 184\n",
      "d_loss 0.7563561201095581\n",
      "epoch 185\n",
      "d_loss 0.48352235555648804\n",
      "epoch 186\n",
      "d_loss 0.7324826717376709\n",
      "epoch 187\n",
      "d_loss 0.6253718733787537\n",
      "epoch 188\n",
      "d_loss 0.5890434384346008\n",
      "epoch 189\n",
      "d_loss 0.4943745732307434\n",
      "epoch 190\n",
      "d_loss 0.6786951422691345\n",
      "epoch 191\n",
      "d_loss 0.6443382501602173\n",
      "epoch 192\n",
      "d_loss 0.5340726971626282\n",
      "epoch 193\n",
      "d_loss 0.4694373607635498\n",
      "epoch 194\n",
      "d_loss 0.6270003318786621\n",
      "epoch 195\n",
      "d_loss 0.6506324410438538\n",
      "epoch 196\n",
      "d_loss 0.4794164299964905\n",
      "epoch 197\n",
      "d_loss 0.5080623030662537\n",
      "epoch 198\n",
      "d_loss 0.5784732103347778\n",
      "epoch 199\n",
      "d_loss 0.5037100315093994\n",
      "epoch 200\n",
      "d_loss 0.45982447266578674\n",
      "epoch 201\n",
      "d_loss 0.5624316930770874\n",
      "epoch 202\n",
      "d_loss 0.4994325637817383\n",
      "epoch 203\n",
      "d_loss 0.543198823928833\n",
      "epoch 204\n",
      "d_loss 0.6299281120300293\n",
      "epoch 205\n",
      "d_loss 0.7657804489135742\n",
      "epoch 206\n",
      "d_loss 0.4648817479610443\n",
      "epoch 207\n",
      "d_loss 0.4637119770050049\n",
      "epoch 208\n",
      "d_loss 0.7599090933799744\n",
      "epoch 209\n",
      "d_loss 0.459651917219162\n",
      "epoch 210\n",
      "d_loss 0.4281124472618103\n",
      "epoch 211\n",
      "d_loss 0.5153970718383789\n",
      "epoch 212\n",
      "d_loss 0.7019988298416138\n",
      "epoch 213\n",
      "d_loss 0.5103877782821655\n",
      "epoch 214\n",
      "d_loss 0.6308008432388306\n",
      "epoch 215\n",
      "d_loss 0.619721531867981\n",
      "epoch 216\n",
      "d_loss 0.6463664174079895\n",
      "epoch 217\n",
      "d_loss 0.5619105100631714\n",
      "epoch 218\n",
      "d_loss 0.6944760680198669\n",
      "epoch 219\n",
      "d_loss 0.5889147520065308\n",
      "epoch 220\n",
      "d_loss 0.45815345644950867\n",
      "epoch 221\n",
      "d_loss 0.459943950176239\n",
      "epoch 222\n",
      "d_loss 0.42727693915367126\n",
      "epoch 223\n",
      "d_loss 0.4292943775653839\n",
      "epoch 224\n",
      "d_loss 0.519032895565033\n",
      "epoch 225\n",
      "d_loss 0.5397546291351318\n",
      "epoch 226\n",
      "d_loss 0.4404330551624298\n",
      "epoch 227\n",
      "d_loss 0.7879520654678345\n",
      "epoch 228\n",
      "d_loss 0.4454568028450012\n",
      "epoch 229\n",
      "d_loss 0.6022524833679199\n",
      "epoch 230\n",
      "d_loss 0.4236736297607422\n",
      "epoch 231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_loss 0.4286300837993622\n",
      "epoch 232\n",
      "d_loss 0.4420667886734009\n",
      "epoch 233\n",
      "d_loss 0.4423062801361084\n",
      "epoch 234\n",
      "d_loss 0.4477206766605377\n",
      "epoch 235\n",
      "d_loss 0.44497203826904297\n",
      "epoch 236\n",
      "d_loss 0.45808202028274536\n",
      "epoch 237\n",
      "d_loss 0.4229184687137604\n",
      "epoch 238\n",
      "d_loss 0.43657904863357544\n",
      "epoch 239\n",
      "d_loss 0.621127724647522\n",
      "epoch 240\n",
      "d_loss 0.6552977561950684\n",
      "epoch 241\n",
      "d_loss 0.45550423860549927\n",
      "epoch 242\n",
      "d_loss 0.4302237033843994\n",
      "epoch 243\n",
      "d_loss 0.43615782260894775\n",
      "epoch 244\n",
      "d_loss 0.4444953203201294\n",
      "epoch 245\n",
      "d_loss 0.4699496924877167\n",
      "epoch 246\n",
      "d_loss 0.6510842442512512\n",
      "epoch 247\n",
      "d_loss 0.518570065498352\n",
      "epoch 248\n",
      "d_loss 0.44627153873443604\n",
      "epoch 249\n",
      "d_loss 0.6632779836654663\n",
      "epoch 250\n",
      "d_loss 0.41510042548179626\n",
      "epoch 251\n",
      "d_loss 0.5065633654594421\n",
      "epoch 252\n",
      "d_loss 0.46488437056541443\n",
      "epoch 253\n",
      "d_loss 0.3992735743522644\n",
      "epoch 254\n",
      "d_loss 0.5072267055511475\n",
      "epoch 255\n",
      "d_loss 0.8381215929985046\n",
      "epoch 256\n",
      "d_loss 0.7733257412910461\n",
      "epoch 257\n",
      "d_loss 0.7314306497573853\n",
      "epoch 258\n",
      "d_loss 0.49021202325820923\n",
      "epoch 259\n",
      "d_loss 0.5362527966499329\n",
      "epoch 260\n",
      "d_loss 0.6705789566040039\n",
      "epoch 261\n",
      "d_loss 0.699216365814209\n",
      "epoch 262\n",
      "d_loss 0.7716466188430786\n",
      "epoch 263\n",
      "d_loss 0.45082637667655945\n",
      "epoch 264\n",
      "d_loss 0.5462651252746582\n",
      "epoch 265\n",
      "d_loss 0.547644853591919\n",
      "epoch 266\n",
      "d_loss 0.7119191884994507\n",
      "epoch 267\n",
      "d_loss 0.8710185289382935\n",
      "epoch 268\n",
      "d_loss 0.4271824359893799\n",
      "epoch 269\n",
      "d_loss 0.4266740381717682\n",
      "epoch 270\n",
      "d_loss 0.6666502952575684\n",
      "epoch 271\n",
      "d_loss 0.49389082193374634\n",
      "epoch 272\n",
      "d_loss 0.49062034487724304\n",
      "epoch 273\n",
      "d_loss 0.5971502661705017\n",
      "epoch 274\n",
      "d_loss 0.6059116125106812\n",
      "epoch 275\n",
      "d_loss 0.3937007784843445\n",
      "epoch 276\n",
      "d_loss 0.8077324032783508\n",
      "epoch 277\n",
      "d_loss 0.6825411319732666\n",
      "epoch 278\n",
      "d_loss 0.6751401424407959\n",
      "epoch 279\n",
      "d_loss 0.7160664200782776\n",
      "epoch 280\n",
      "d_loss 0.4435516893863678\n",
      "epoch 281\n",
      "d_loss 0.7059417963027954\n",
      "epoch 282\n",
      "d_loss 0.49504566192626953\n",
      "epoch 283\n",
      "d_loss 0.4444834291934967\n",
      "epoch 284\n",
      "d_loss 0.466237872838974\n",
      "epoch 285\n",
      "d_loss 0.5470539331436157\n",
      "epoch 286\n",
      "d_loss 0.4052738845348358\n",
      "epoch 287\n",
      "d_loss 0.7796230912208557\n",
      "epoch 288\n",
      "d_loss 0.45965850353240967\n",
      "epoch 289\n",
      "d_loss 0.42256277799606323\n",
      "epoch 290\n",
      "d_loss 0.8309643268585205\n",
      "epoch 291\n",
      "d_loss 0.4215269982814789\n",
      "epoch 292\n",
      "d_loss 0.4384171962738037\n",
      "epoch 293\n",
      "d_loss 0.9441570043563843\n",
      "epoch 294\n",
      "d_loss 0.6521841883659363\n",
      "epoch 295\n",
      "d_loss 0.6317659616470337\n",
      "epoch 296\n",
      "d_loss 0.8205817341804504\n",
      "epoch 297\n",
      "d_loss 0.46219825744628906\n",
      "epoch 298\n",
      "d_loss 0.46732616424560547\n",
      "epoch 299\n",
      "d_loss 0.4240589141845703\n"
     ]
    }
   ],
   "source": [
    "for e in range(300):\n",
    "    print('epoch', e)\n",
    "    data = gen.flow_from_directory().__next__()\n",
    "    X_low = data[0]\n",
    "    X_high = data[1]\n",
    "    srgan.train(X_low, X_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "d_loss 0.39597558975219727\n",
      "epoch 1\n",
      "d_loss 0.5304909944534302\n",
      "epoch 2\n",
      "d_loss 0.4395718276500702\n",
      "epoch 3\n",
      "d_loss 0.5215224027633667\n",
      "epoch 4\n",
      "d_loss 0.5594314336776733\n",
      "epoch 5\n",
      "d_loss 0.6165004968643188\n",
      "epoch 6\n",
      "d_loss 0.4410811960697174\n",
      "epoch 7\n",
      "d_loss 0.4018663763999939\n",
      "epoch 8\n",
      "d_loss 0.5353365540504456\n",
      "epoch 9\n",
      "d_loss 0.799946129322052\n",
      "epoch 10\n",
      "d_loss 0.3756040930747986\n",
      "epoch 11\n",
      "d_loss 0.6670982837677002\n",
      "epoch 12\n",
      "d_loss 0.6799257397651672\n",
      "epoch 13\n",
      "d_loss 0.42741066217422485\n",
      "epoch 14\n",
      "d_loss 0.41102588176727295\n",
      "epoch 15\n",
      "d_loss 0.37047576904296875\n",
      "epoch 16\n",
      "d_loss 0.4418758451938629\n",
      "epoch 17\n",
      "d_loss 0.4229797124862671\n",
      "epoch 18\n",
      "d_loss 0.455262690782547\n",
      "epoch 19\n",
      "d_loss 0.4033775329589844\n",
      "epoch 20\n",
      "d_loss 0.39344048500061035\n",
      "epoch 21\n",
      "d_loss 0.3929494619369507\n",
      "epoch 22\n",
      "d_loss 0.591873049736023\n",
      "epoch 23\n",
      "d_loss 0.8030902147293091\n",
      "epoch 24\n",
      "d_loss 0.4402567148208618\n",
      "epoch 25\n",
      "d_loss 0.4327717423439026\n",
      "epoch 26\n",
      "d_loss 0.41391366720199585\n",
      "epoch 27\n",
      "d_loss 0.3904991149902344\n",
      "epoch 28\n",
      "d_loss 0.5039258003234863\n",
      "epoch 29\n",
      "d_loss 0.7377023100852966\n",
      "epoch 30\n",
      "d_loss 0.39767396450042725\n",
      "epoch 31\n",
      "d_loss 0.3857927918434143\n",
      "epoch 32\n",
      "d_loss 0.3462991714477539\n",
      "epoch 33\n",
      "d_loss 0.4498557448387146\n",
      "epoch 34\n",
      "d_loss 0.5080425143241882\n",
      "epoch 35\n",
      "d_loss 0.34916409850120544\n",
      "epoch 36\n",
      "d_loss 0.37086254358291626\n",
      "epoch 37\n",
      "d_loss 0.47057294845581055\n",
      "epoch 38\n",
      "d_loss 0.47732335329055786\n",
      "epoch 39\n",
      "d_loss 0.45175665616989136\n",
      "epoch 40\n",
      "d_loss 0.3668517470359802\n",
      "epoch 41\n",
      "d_loss 0.3949117660522461\n",
      "epoch 42\n",
      "d_loss 0.34316420555114746\n",
      "epoch 43\n",
      "d_loss 0.4280215799808502\n",
      "epoch 44\n",
      "d_loss 0.4132375121116638\n",
      "epoch 45\n",
      "d_loss 0.3599041700363159\n",
      "epoch 46\n",
      "d_loss 0.6926101446151733\n",
      "epoch 47\n",
      "d_loss 0.7258977890014648\n",
      "epoch 48\n",
      "d_loss 0.4622553586959839\n",
      "epoch 49\n",
      "d_loss 0.3472302556037903\n",
      "epoch 50\n",
      "d_loss 0.3557209372520447\n",
      "epoch 51\n",
      "d_loss 0.36790627241134644\n",
      "epoch 52\n",
      "d_loss 0.38107526302337646\n",
      "epoch 53\n",
      "d_loss 0.32204562425613403\n",
      "epoch 54\n",
      "d_loss 0.4468974471092224\n",
      "epoch 55\n",
      "d_loss 0.4363005757331848\n",
      "epoch 56\n",
      "d_loss 0.6658328771591187\n",
      "epoch 57\n",
      "d_loss 0.7536720633506775\n",
      "epoch 58\n",
      "d_loss 0.4291619062423706\n",
      "epoch 59\n",
      "d_loss 0.5281237363815308\n",
      "epoch 60\n",
      "d_loss 0.5196616649627686\n",
      "epoch 61\n",
      "d_loss 0.6516419649124146\n",
      "epoch 62\n",
      "d_loss 0.8083627223968506\n",
      "epoch 63\n",
      "d_loss 0.4156753122806549\n",
      "epoch 64\n",
      "d_loss 0.6929652690887451\n",
      "epoch 65\n",
      "d_loss 0.42837607860565186\n",
      "epoch 66\n",
      "d_loss 0.6481543779373169\n",
      "epoch 67\n",
      "d_loss 0.5012932419776917\n",
      "epoch 68\n",
      "d_loss 0.5215014219284058\n",
      "epoch 69\n",
      "d_loss 0.46676743030548096\n",
      "epoch 70\n",
      "d_loss 0.3247242271900177\n",
      "epoch 71\n",
      "d_loss 0.6745772361755371\n",
      "epoch 72\n",
      "d_loss 0.382526695728302\n",
      "epoch 73\n",
      "d_loss 0.3529985845088959\n",
      "epoch 74\n",
      "d_loss 0.35238444805145264\n",
      "epoch 75\n",
      "d_loss 0.3947524428367615\n",
      "epoch 76\n",
      "d_loss 0.3502367436885834\n",
      "epoch 77\n",
      "d_loss 0.3193012773990631\n",
      "epoch 78\n",
      "d_loss 0.46190309524536133\n",
      "epoch 79\n",
      "d_loss 0.49201709032058716\n",
      "epoch 80\n",
      "d_loss 0.4366374611854553\n",
      "epoch 81\n",
      "d_loss 0.30804669857025146\n",
      "epoch 82\n",
      "d_loss 0.4022807478904724\n",
      "epoch 83\n",
      "d_loss 0.3164786696434021\n",
      "epoch 84\n",
      "d_loss 0.3487550616264343\n",
      "epoch 85\n",
      "d_loss 0.31191137433052063\n",
      "epoch 86\n",
      "d_loss 0.4278523325920105\n",
      "epoch 87\n",
      "d_loss 0.4042304456233978\n",
      "epoch 88\n",
      "d_loss 0.30621087551116943\n",
      "epoch 89\n",
      "d_loss 0.31007710099220276\n",
      "epoch 90\n",
      "d_loss 0.5550594329833984\n",
      "epoch 91\n",
      "d_loss 0.2916150689125061\n",
      "epoch 92\n",
      "d_loss 0.3982464075088501\n",
      "epoch 93\n",
      "d_loss 0.6107608079910278\n",
      "epoch 94\n",
      "d_loss 0.39198797941207886\n",
      "epoch 95\n",
      "d_loss 0.2817552983760834\n",
      "epoch 96\n",
      "d_loss 0.3771284818649292\n",
      "epoch 97\n",
      "d_loss 0.36079299449920654\n",
      "epoch 98\n",
      "d_loss 0.33335691690444946\n",
      "epoch 99\n",
      "d_loss 0.3733333647251129\n",
      "epoch 100\n",
      "d_loss 0.3750188648700714\n",
      "epoch 101\n",
      "d_loss 0.3535681962966919\n",
      "epoch 102\n",
      "d_loss 0.31642675399780273\n",
      "epoch 103\n",
      "d_loss 0.3336385190486908\n",
      "epoch 104\n",
      "d_loss 0.45825812220573425\n",
      "epoch 105\n",
      "d_loss 0.32611674070358276\n",
      "epoch 106\n",
      "d_loss 0.41866961121559143\n",
      "epoch 107\n",
      "d_loss 0.2873839735984802\n",
      "epoch 108\n",
      "d_loss 0.5165473222732544\n",
      "epoch 109\n",
      "d_loss 0.8093574047088623\n",
      "epoch 110\n",
      "d_loss 0.27877625823020935\n",
      "epoch 111\n",
      "d_loss 0.7660456299781799\n",
      "epoch 112\n",
      "d_loss 0.38112080097198486\n",
      "epoch 113\n",
      "d_loss 0.30364784598350525\n",
      "epoch 114\n",
      "d_loss 0.2818869948387146\n",
      "epoch 115\n",
      "d_loss 0.7274774312973022\n",
      "epoch 116\n",
      "d_loss 0.3503193259239197\n",
      "epoch 117\n",
      "d_loss 0.2970389723777771\n",
      "epoch 118\n",
      "d_loss 0.9251061677932739\n",
      "epoch 119\n",
      "d_loss 0.31956374645233154\n",
      "epoch 120\n",
      "d_loss 0.31530094146728516\n",
      "epoch 121\n",
      "d_loss 0.46051859855651855\n",
      "epoch 122\n",
      "d_loss 0.3483631908893585\n",
      "epoch 123\n",
      "d_loss 0.4094494581222534\n",
      "epoch 124\n",
      "d_loss 0.30441832542419434\n",
      "epoch 125\n",
      "d_loss 0.26916903257369995\n",
      "epoch 126\n",
      "d_loss 0.6234040260314941\n",
      "epoch 127\n",
      "d_loss 0.6769992113113403\n",
      "epoch 128\n",
      "d_loss 0.48578745126724243\n",
      "epoch 129\n",
      "d_loss 0.3057156205177307\n",
      "epoch 130\n",
      "d_loss 0.4557124078273773\n",
      "epoch 131\n",
      "d_loss 0.43908584117889404\n",
      "epoch 132\n",
      "d_loss 0.30914101004600525\n",
      "epoch 133\n",
      "d_loss 0.3213662803173065\n",
      "epoch 134\n",
      "d_loss 0.32344916462898254\n",
      "epoch 135\n",
      "d_loss 0.3928276598453522\n",
      "epoch 136\n",
      "d_loss 0.2707424759864807\n",
      "epoch 137\n",
      "d_loss 0.3691929578781128\n",
      "epoch 138\n",
      "d_loss 0.49478960037231445\n",
      "epoch 139\n",
      "d_loss 0.28609758615493774\n",
      "epoch 140\n",
      "d_loss 0.29654502868652344\n",
      "epoch 141\n",
      "d_loss 0.385525107383728\n",
      "epoch 142\n",
      "d_loss 0.28773558139801025\n",
      "epoch 143\n",
      "d_loss 0.2890516519546509\n",
      "epoch 144\n",
      "d_loss 0.3088380694389343\n",
      "epoch 145\n",
      "d_loss 0.2673085927963257\n",
      "epoch 146\n",
      "d_loss 0.3802300691604614\n",
      "epoch 147\n",
      "d_loss 0.26543039083480835\n",
      "epoch 148\n",
      "d_loss 0.6339271664619446\n",
      "epoch 149\n",
      "d_loss 0.25819000601768494\n",
      "epoch 150\n",
      "d_loss 0.688823938369751\n",
      "epoch 151\n",
      "d_loss 0.4464229941368103\n",
      "epoch 152\n",
      "d_loss 0.8556849956512451\n",
      "epoch 153\n",
      "d_loss 0.27069488167762756\n",
      "epoch 154\n",
      "d_loss 0.5206840634346008\n",
      "epoch 155\n",
      "d_loss 0.4214273691177368\n",
      "epoch 156\n",
      "d_loss 0.26827186346054077\n",
      "epoch 157\n",
      "d_loss 0.48655015230178833\n",
      "epoch 158\n",
      "d_loss 0.23917677998542786\n",
      "epoch 159\n",
      "d_loss 0.3225860297679901\n",
      "epoch 160\n",
      "d_loss 0.8842363953590393\n",
      "epoch 161\n",
      "d_loss 0.8855405449867249\n",
      "epoch 162\n",
      "d_loss 0.8888000249862671\n",
      "epoch 163\n",
      "d_loss 0.9426871538162231\n",
      "epoch 164\n",
      "d_loss 0.8680624961853027\n",
      "epoch 165\n",
      "d_loss 0.8641303777694702\n",
      "epoch 166\n",
      "d_loss 0.9084048271179199\n",
      "epoch 167\n",
      "d_loss 0.8513423204421997\n",
      "epoch 168\n",
      "d_loss 0.8387330174446106\n",
      "epoch 169\n",
      "d_loss 0.8311734795570374\n",
      "epoch 170\n",
      "d_loss 0.8224649429321289\n",
      "epoch 171\n",
      "d_loss 0.7642545700073242\n",
      "epoch 172\n",
      "d_loss 0.865989089012146\n",
      "epoch 173\n",
      "d_loss 0.8843206763267517\n",
      "epoch 174\n",
      "d_loss 0.8172399997711182\n",
      "epoch 175\n",
      "d_loss 0.8184155225753784\n",
      "epoch 176\n",
      "d_loss 0.7715843915939331\n",
      "epoch 177\n",
      "d_loss 0.6932066679000854\n",
      "epoch 178\n",
      "d_loss 0.7078515887260437\n",
      "epoch 179\n",
      "d_loss 0.8098584413528442\n",
      "epoch 180\n",
      "d_loss 0.7417582869529724\n",
      "epoch 181\n",
      "d_loss 0.7894077301025391\n",
      "epoch 182\n",
      "d_loss 0.9836574792861938\n",
      "epoch 183\n",
      "d_loss 0.7563742399215698\n",
      "epoch 184\n",
      "d_loss 0.7848395705223083\n",
      "epoch 185\n",
      "d_loss 0.7964787483215332\n",
      "epoch 186\n",
      "d_loss 0.7666076421737671\n",
      "epoch 187\n",
      "d_loss 0.7720818519592285\n",
      "epoch 188\n",
      "d_loss 0.7316809296607971\n",
      "epoch 189\n",
      "d_loss 0.7789933681488037\n",
      "epoch 190\n",
      "d_loss 0.767767608165741\n",
      "epoch 191\n",
      "d_loss 0.7972416877746582\n",
      "epoch 192\n",
      "d_loss 0.8798954486846924\n",
      "epoch 193\n",
      "d_loss 0.7840967178344727\n",
      "epoch 194\n",
      "d_loss 0.7472139596939087\n",
      "epoch 195\n",
      "d_loss 0.7862714529037476\n",
      "epoch 196\n",
      "d_loss 0.7358176112174988\n",
      "epoch 197\n",
      "d_loss 0.7415411472320557\n",
      "epoch 198\n",
      "d_loss 0.7380326390266418\n",
      "epoch 199\n",
      "d_loss 0.6561323404312134\n",
      "epoch 200\n",
      "d_loss 0.5343115329742432\n",
      "epoch 201\n",
      "d_loss 0.4108384847640991\n",
      "epoch 202\n",
      "d_loss 0.7387431859970093\n",
      "epoch 203\n",
      "d_loss 0.7345072031021118\n",
      "epoch 204\n",
      "d_loss 0.7331987619400024\n",
      "epoch 205\n",
      "d_loss 0.7368091344833374\n",
      "epoch 206\n",
      "d_loss 0.7310213446617126\n",
      "epoch 207\n",
      "d_loss 0.7577320337295532\n",
      "epoch 208\n",
      "d_loss 0.6782037615776062\n",
      "epoch 209\n",
      "d_loss 0.7313427925109863\n",
      "epoch 210\n",
      "d_loss 0.72674560546875\n",
      "epoch 211\n",
      "d_loss 0.7330750823020935\n",
      "epoch 212\n",
      "d_loss 0.6791473627090454\n",
      "epoch 213\n",
      "d_loss 1.053588628768921\n",
      "epoch 214\n",
      "d_loss 0.5625026822090149\n",
      "epoch 215\n",
      "d_loss 0.4090275764465332\n",
      "epoch 216\n",
      "d_loss 0.33398860692977905\n",
      "epoch 217\n",
      "d_loss 0.9276116490364075\n",
      "epoch 218\n",
      "d_loss 0.3483524024486542\n",
      "epoch 219\n",
      "d_loss 0.9409351944923401\n",
      "epoch 220\n",
      "d_loss 0.4525053799152374\n",
      "epoch 221\n",
      "d_loss 0.6897259950637817\n",
      "epoch 222\n",
      "d_loss 0.7353271245956421\n",
      "epoch 223\n",
      "d_loss 0.8380188941955566\n",
      "epoch 224\n",
      "d_loss 0.7411677837371826\n",
      "epoch 225\n",
      "d_loss 0.7332615852355957\n",
      "epoch 226\n",
      "d_loss 0.7222525477409363\n",
      "epoch 227\n",
      "d_loss 0.7293306589126587\n",
      "epoch 228\n",
      "d_loss 0.6786018013954163\n",
      "epoch 229\n",
      "d_loss 0.966170608997345\n",
      "epoch 230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_loss 0.7268756628036499\n",
      "epoch 231\n",
      "d_loss 0.7323498725891113\n",
      "epoch 232\n",
      "d_loss 0.7221062183380127\n",
      "epoch 233\n",
      "d_loss 0.700251579284668\n",
      "epoch 234\n",
      "d_loss 0.6887726783752441\n",
      "epoch 235\n",
      "d_loss 0.722901463508606\n",
      "epoch 236\n",
      "d_loss 0.4948102831840515\n",
      "epoch 237\n",
      "d_loss 0.6520249843597412\n",
      "epoch 238\n",
      "d_loss 0.7736943960189819\n",
      "epoch 239\n",
      "d_loss 0.9658308029174805\n",
      "epoch 240\n",
      "d_loss 0.7318357825279236\n",
      "epoch 241\n",
      "d_loss 0.7364596724510193\n",
      "epoch 242\n",
      "d_loss 0.6925240159034729\n",
      "epoch 243\n",
      "d_loss 0.7247145175933838\n",
      "epoch 244\n",
      "d_loss 0.7453925609588623\n",
      "epoch 245\n",
      "d_loss 0.6834129691123962\n",
      "epoch 246\n",
      "d_loss 0.6908501982688904\n",
      "epoch 247\n",
      "d_loss 0.7141355276107788\n",
      "epoch 248\n",
      "d_loss 0.7785138487815857\n",
      "epoch 249\n",
      "d_loss 0.7431244254112244\n",
      "epoch 250\n",
      "d_loss 0.7219855189323425\n",
      "epoch 251\n",
      "d_loss 0.7095108032226562\n",
      "epoch 252\n",
      "d_loss 0.6706894636154175\n",
      "epoch 253\n",
      "d_loss 0.6640652418136597\n",
      "epoch 254\n",
      "d_loss 0.8229772448539734\n",
      "epoch 255\n",
      "d_loss 0.8120665550231934\n",
      "epoch 256\n",
      "d_loss 0.6932907104492188\n",
      "epoch 257\n",
      "d_loss 0.5247886180877686\n",
      "epoch 258\n",
      "d_loss 0.4572041630744934\n",
      "epoch 259\n",
      "d_loss 0.4783536195755005\n",
      "epoch 260\n",
      "d_loss 0.7143563032150269\n",
      "epoch 261\n",
      "d_loss 0.6571325063705444\n",
      "epoch 262\n",
      "d_loss 0.7374563217163086\n",
      "epoch 263\n",
      "d_loss 0.8153595924377441\n",
      "epoch 264\n",
      "d_loss 0.5607497096061707\n",
      "epoch 265\n",
      "d_loss 0.7130106687545776\n",
      "epoch 266\n",
      "d_loss 0.6877880096435547\n",
      "epoch 267\n",
      "d_loss 0.7343572378158569\n",
      "epoch 268\n",
      "d_loss 0.8874028325080872\n",
      "epoch 269\n",
      "d_loss 0.5264105796813965\n",
      "epoch 270\n",
      "d_loss 0.826488196849823\n",
      "epoch 271\n",
      "d_loss 0.5081901550292969\n",
      "epoch 272\n",
      "d_loss 0.8626600503921509\n",
      "epoch 273\n",
      "d_loss 1.130446195602417\n",
      "epoch 274\n",
      "d_loss 0.7305741310119629\n",
      "epoch 275\n",
      "d_loss 0.7352160215377808\n",
      "epoch 276\n",
      "d_loss 0.7081571817398071\n",
      "epoch 277\n",
      "d_loss 0.9570251107215881\n",
      "epoch 278\n",
      "d_loss 0.46746760606765747\n",
      "epoch 279\n",
      "d_loss 0.7280430197715759\n",
      "epoch 280\n",
      "d_loss 0.8151673078536987\n",
      "epoch 281\n",
      "d_loss 0.7371513247489929\n",
      "epoch 282\n",
      "d_loss 0.7578991651535034\n",
      "epoch 283\n",
      "d_loss 0.5336079597473145\n",
      "epoch 284\n",
      "d_loss 0.7549574375152588\n",
      "epoch 285\n",
      "d_loss 0.9257885217666626\n",
      "epoch 286\n",
      "d_loss 0.5224475860595703\n",
      "epoch 287\n",
      "d_loss 0.8921445608139038\n",
      "epoch 288\n",
      "d_loss 0.8024625778198242\n",
      "epoch 289\n",
      "d_loss 0.8351224064826965\n",
      "epoch 290\n",
      "d_loss 0.8039453029632568\n",
      "epoch 291\n",
      "d_loss 0.7898229360580444\n",
      "epoch 292\n",
      "d_loss 0.7518830895423889\n",
      "epoch 293\n",
      "d_loss 0.705396294593811\n",
      "epoch 294\n",
      "d_loss 0.7283505201339722\n",
      "epoch 295\n",
      "d_loss 0.7420574426651001\n",
      "epoch 296\n",
      "d_loss 0.7529022097587585\n",
      "epoch 297\n",
      "d_loss 0.8375956416130066\n",
      "epoch 298\n",
      "d_loss 0.6999743580818176\n",
      "epoch 299\n",
      "d_loss 0.6621059775352478\n"
     ]
    }
   ],
   "source": [
    "for e in range(300):\n",
    "    print('epoch', e)\n",
    "    data = gen.flow_from_directory().__next__()\n",
    "    X_low = data[0]\n",
    "    X_high = data[1]\n",
    "    srgan.train(X_low, X_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "d_loss 0.7310494184494019\n",
      "epoch 1\n",
      "d_loss 0.9272258281707764\n",
      "epoch 2\n",
      "d_loss 0.698296070098877\n",
      "epoch 3\n",
      "d_loss 0.9986585974693298\n",
      "epoch 4\n",
      "d_loss 0.924297034740448\n",
      "epoch 5\n",
      "d_loss 0.7160964012145996\n",
      "epoch 6\n",
      "d_loss 0.7189580202102661\n",
      "epoch 7\n",
      "d_loss 0.728611171245575\n",
      "epoch 8\n",
      "d_loss 0.7693494558334351\n",
      "epoch 9\n",
      "d_loss 0.7241849899291992\n",
      "epoch 10\n",
      "d_loss 0.9891711473464966\n",
      "epoch 11\n",
      "d_loss 0.847419023513794\n",
      "epoch 12\n",
      "d_loss 0.7347081899642944\n",
      "epoch 13\n",
      "d_loss 0.7130287885665894\n",
      "epoch 14\n",
      "d_loss 0.7277429103851318\n",
      "epoch 15\n",
      "d_loss 0.7764166593551636\n",
      "epoch 16\n",
      "d_loss 0.684158205986023\n",
      "epoch 17\n",
      "d_loss 0.7190741300582886\n",
      "epoch 18\n",
      "d_loss 0.9144037961959839\n",
      "epoch 19\n",
      "d_loss 0.7054049968719482\n",
      "epoch 20\n",
      "d_loss 0.9139178395271301\n",
      "epoch 21\n",
      "d_loss 0.7398450374603271\n",
      "epoch 22\n",
      "d_loss 0.7289597392082214\n",
      "epoch 23\n",
      "d_loss 0.6949272751808167\n",
      "epoch 24\n",
      "d_loss 0.7318724393844604\n",
      "epoch 25\n",
      "d_loss 0.7265743017196655\n",
      "epoch 26\n",
      "d_loss 0.8762224912643433\n",
      "epoch 27\n",
      "d_loss 0.7194879651069641\n",
      "epoch 28\n",
      "d_loss 0.8373282551765442\n",
      "epoch 29\n",
      "d_loss 0.7108737230300903\n",
      "epoch 30\n",
      "d_loss 0.7081231474876404\n",
      "epoch 31\n",
      "d_loss 0.7310752868652344\n",
      "epoch 32\n",
      "d_loss 0.7282653450965881\n",
      "epoch 33\n",
      "d_loss 0.7124217748641968\n",
      "epoch 34\n",
      "d_loss 0.7344426512718201\n",
      "epoch 35\n",
      "d_loss 0.7826144695281982\n",
      "epoch 36\n",
      "d_loss 0.7397365570068359\n",
      "epoch 37\n",
      "d_loss 0.7050473690032959\n",
      "epoch 38\n",
      "d_loss 0.7169544696807861\n",
      "epoch 39\n",
      "d_loss 0.809654951095581\n",
      "epoch 40\n",
      "d_loss 0.9140225648880005\n",
      "epoch 41\n",
      "d_loss 0.7453696727752686\n",
      "epoch 42\n",
      "d_loss 0.7061131596565247\n",
      "epoch 43\n",
      "d_loss 0.7025356292724609\n",
      "epoch 44\n",
      "d_loss 0.7744907140731812\n",
      "epoch 45\n",
      "d_loss 0.6981393098831177\n",
      "epoch 46\n",
      "d_loss 0.7096285820007324\n",
      "epoch 47\n",
      "d_loss 0.8353768587112427\n",
      "epoch 48\n",
      "d_loss 0.7261943221092224\n",
      "epoch 49\n",
      "d_loss 0.7127613425254822\n",
      "epoch 50\n",
      "d_loss 0.7848758101463318\n",
      "epoch 51\n",
      "d_loss 0.8206446170806885\n",
      "epoch 52\n",
      "d_loss 0.7129679322242737\n",
      "epoch 53\n",
      "d_loss 0.6597417593002319\n",
      "epoch 54\n",
      "d_loss 0.6417621970176697\n",
      "epoch 55\n",
      "d_loss 0.715226411819458\n",
      "epoch 56\n",
      "d_loss 0.7215186357498169\n",
      "epoch 57\n",
      "d_loss 0.7056150436401367\n",
      "epoch 58\n",
      "d_loss 0.7741278409957886\n",
      "epoch 59\n",
      "d_loss 0.753815233707428\n",
      "epoch 60\n",
      "d_loss 0.7826000452041626\n",
      "epoch 61\n",
      "d_loss 0.7607647776603699\n",
      "epoch 62\n",
      "d_loss 0.6707265973091125\n",
      "epoch 63\n",
      "d_loss 0.6701582670211792\n",
      "epoch 64\n",
      "d_loss 0.6121982336044312\n",
      "epoch 65\n",
      "d_loss 0.867158055305481\n",
      "epoch 66\n",
      "d_loss 0.6944930553436279\n",
      "epoch 67\n",
      "d_loss 0.6438554525375366\n",
      "epoch 68\n",
      "d_loss 0.6944591999053955\n",
      "epoch 69\n",
      "d_loss 0.7262190580368042\n",
      "epoch 70\n",
      "d_loss 0.6933832168579102\n",
      "epoch 71\n",
      "d_loss 0.7165164351463318\n",
      "epoch 72\n",
      "d_loss 0.7203641533851624\n",
      "epoch 73\n",
      "d_loss 0.8060858249664307\n",
      "epoch 74\n",
      "d_loss 0.700400710105896\n",
      "epoch 75\n",
      "d_loss 0.7068797945976257\n",
      "epoch 76\n",
      "d_loss 0.7508687376976013\n",
      "epoch 77\n",
      "d_loss 0.7127567529678345\n",
      "epoch 78\n",
      "d_loss 0.8641948699951172\n",
      "epoch 79\n",
      "d_loss 0.6850256323814392\n",
      "epoch 80\n",
      "d_loss 0.7925091981887817\n",
      "epoch 81\n",
      "d_loss 0.6636044383049011\n",
      "epoch 82\n",
      "d_loss 0.7594678401947021\n",
      "epoch 83\n",
      "d_loss 0.6900415420532227\n",
      "epoch 84\n",
      "d_loss 0.690246045589447\n",
      "epoch 85\n",
      "d_loss 0.7482554912567139\n",
      "epoch 86\n",
      "d_loss 0.7191176414489746\n",
      "epoch 87\n",
      "d_loss 0.664905309677124\n",
      "epoch 88\n",
      "d_loss 0.7026735544204712\n",
      "epoch 89\n",
      "d_loss 0.9039120674133301\n",
      "epoch 90\n",
      "d_loss 0.8148932456970215\n",
      "epoch 91\n",
      "d_loss 0.6764180660247803\n",
      "epoch 92\n",
      "d_loss 0.727779746055603\n",
      "epoch 93\n",
      "d_loss 0.7235839366912842\n",
      "epoch 94\n",
      "d_loss 0.8761146068572998\n",
      "epoch 95\n",
      "d_loss 0.7685367465019226\n",
      "epoch 96\n",
      "d_loss 0.7425652742385864\n",
      "epoch 97\n",
      "d_loss 0.7310660481452942\n",
      "epoch 98\n",
      "d_loss 0.7687829732894897\n",
      "epoch 99\n",
      "d_loss 0.7174177765846252\n",
      "epoch 100\n",
      "d_loss 0.6884135007858276\n",
      "epoch 101\n",
      "d_loss 0.7092888951301575\n",
      "epoch 102\n",
      "d_loss 0.7521389126777649\n",
      "epoch 103\n",
      "d_loss 0.6992933750152588\n",
      "epoch 104\n",
      "d_loss 0.8223294019699097\n",
      "epoch 105\n",
      "d_loss 0.6806097030639648\n",
      "epoch 106\n",
      "d_loss 0.7684453725814819\n",
      "epoch 107\n",
      "d_loss 0.6915109157562256\n",
      "epoch 108\n",
      "d_loss 0.5692118406295776\n",
      "epoch 109\n",
      "d_loss 0.8226413726806641\n",
      "epoch 110\n",
      "d_loss 0.649693489074707\n",
      "epoch 111\n",
      "d_loss 0.5478212833404541\n",
      "epoch 112\n",
      "d_loss 0.8609189987182617\n",
      "epoch 113\n",
      "d_loss 0.8003829121589661\n",
      "epoch 114\n",
      "d_loss 0.7503730654716492\n",
      "epoch 115\n",
      "d_loss 0.8116728663444519\n",
      "epoch 116\n",
      "d_loss 0.7221850156784058\n",
      "epoch 117\n",
      "d_loss 0.7952125668525696\n",
      "epoch 118\n",
      "d_loss 0.707443118095398\n",
      "epoch 119\n",
      "d_loss 0.7424094676971436\n",
      "epoch 120\n",
      "d_loss 0.7646235823631287\n",
      "epoch 121\n",
      "d_loss 0.7284705638885498\n",
      "epoch 122\n",
      "d_loss 0.7014086246490479\n",
      "epoch 123\n",
      "d_loss 0.7729949355125427\n",
      "epoch 124\n",
      "d_loss 0.6264104843139648\n",
      "epoch 125\n",
      "d_loss 0.7276954650878906\n",
      "epoch 126\n",
      "d_loss 0.685353696346283\n",
      "epoch 127\n",
      "d_loss 0.6199008822441101\n",
      "epoch 128\n",
      "d_loss 0.7035194635391235\n",
      "epoch 129\n",
      "d_loss 0.7298837304115295\n",
      "epoch 130\n",
      "d_loss 0.7764438986778259\n",
      "epoch 131\n",
      "d_loss 0.7113958597183228\n",
      "epoch 132\n",
      "d_loss 0.7234117984771729\n",
      "epoch 133\n",
      "d_loss 0.7032139301300049\n",
      "epoch 134\n",
      "d_loss 0.7154205441474915\n",
      "epoch 135\n",
      "d_loss 0.8550757765769958\n",
      "epoch 136\n",
      "d_loss 0.686297595500946\n",
      "epoch 137\n",
      "d_loss 0.7117290496826172\n",
      "epoch 138\n",
      "d_loss 0.6958931684494019\n",
      "epoch 139\n",
      "d_loss 0.6706113219261169\n",
      "epoch 140\n",
      "d_loss 0.7442281246185303\n",
      "epoch 141\n",
      "d_loss 0.685802698135376\n",
      "epoch 142\n",
      "d_loss 0.7326128482818604\n",
      "epoch 143\n",
      "d_loss 0.5728144645690918\n",
      "epoch 144\n",
      "d_loss 0.6660376787185669\n",
      "epoch 145\n",
      "d_loss 0.6568630933761597\n",
      "epoch 146\n",
      "d_loss 0.7305800914764404\n",
      "epoch 147\n",
      "d_loss 0.7366166114807129\n",
      "epoch 148\n",
      "d_loss 0.7923694252967834\n",
      "epoch 149\n",
      "d_loss 0.6993218660354614\n",
      "epoch 150\n",
      "d_loss 0.7286592721939087\n",
      "epoch 151\n",
      "d_loss 0.7606390714645386\n",
      "epoch 152\n",
      "d_loss 0.661590576171875\n",
      "epoch 153\n",
      "d_loss 0.7572807669639587\n",
      "epoch 154\n",
      "d_loss 0.7202736735343933\n",
      "epoch 155\n",
      "d_loss 0.7265855073928833\n",
      "epoch 156\n",
      "d_loss 0.7174087166786194\n",
      "epoch 157\n",
      "d_loss 0.7125856280326843\n",
      "epoch 158\n",
      "d_loss 0.6811558604240417\n",
      "epoch 159\n",
      "d_loss 0.6987695693969727\n",
      "epoch 160\n",
      "d_loss 0.5513943433761597\n",
      "epoch 161\n",
      "d_loss 0.5420615673065186\n",
      "epoch 162\n",
      "d_loss 0.7353218793869019\n",
      "epoch 163\n",
      "d_loss 0.7071237564086914\n",
      "epoch 164\n",
      "d_loss 0.6298800706863403\n",
      "epoch 165\n",
      "d_loss 0.7023232579231262\n",
      "epoch 166\n",
      "d_loss 0.7180541753768921\n",
      "epoch 167\n",
      "d_loss 0.5961599349975586\n",
      "epoch 168\n",
      "d_loss 0.7025051116943359\n",
      "epoch 169\n",
      "d_loss 0.700875997543335\n",
      "epoch 170\n",
      "d_loss 0.7038413286209106\n",
      "epoch 171\n",
      "d_loss 0.6732935309410095\n",
      "epoch 172\n",
      "d_loss 0.723421573638916\n",
      "epoch 173\n",
      "d_loss 0.7393572926521301\n",
      "epoch 174\n",
      "d_loss 0.7212827205657959\n",
      "epoch 175\n",
      "d_loss 0.6928564310073853\n",
      "epoch 176\n",
      "d_loss 0.7286619544029236\n",
      "epoch 177\n",
      "d_loss 0.7135765552520752\n",
      "epoch 178\n",
      "d_loss 0.7215766906738281\n",
      "epoch 179\n",
      "d_loss 0.5278377532958984\n",
      "epoch 180\n",
      "d_loss 0.7073360681533813\n",
      "epoch 181\n",
      "d_loss 0.681584894657135\n",
      "epoch 182\n",
      "d_loss 0.6532257795333862\n",
      "epoch 183\n",
      "d_loss 0.6982580423355103\n",
      "epoch 184\n",
      "d_loss 0.6186560392379761\n",
      "epoch 185\n",
      "d_loss 0.6940891742706299\n",
      "epoch 186\n",
      "d_loss 0.7147398591041565\n",
      "epoch 187\n",
      "d_loss 0.7724984884262085\n",
      "epoch 188\n",
      "d_loss 0.6676726341247559\n",
      "epoch 189\n",
      "d_loss 0.8238567113876343\n",
      "epoch 190\n",
      "d_loss 0.6918463706970215\n",
      "epoch 191\n",
      "d_loss 0.7198549509048462\n",
      "epoch 192\n",
      "d_loss 0.7329534292221069\n",
      "epoch 193\n",
      "d_loss 0.7310152053833008\n",
      "epoch 194\n",
      "d_loss 0.6538318395614624\n",
      "epoch 195\n",
      "d_loss 0.5611733198165894\n",
      "epoch 196\n",
      "d_loss 0.6647379994392395\n",
      "epoch 197\n",
      "d_loss 0.720302939414978\n",
      "epoch 198\n",
      "d_loss 0.8606575131416321\n",
      "epoch 199\n",
      "d_loss 0.7133534550666809\n",
      "epoch 200\n",
      "d_loss 0.7759842276573181\n",
      "epoch 201\n",
      "d_loss 0.5726051330566406\n",
      "epoch 202\n",
      "d_loss 0.698959469795227\n",
      "epoch 203\n",
      "d_loss 0.7156723141670227\n",
      "epoch 204\n",
      "d_loss 0.6898480653762817\n",
      "epoch 205\n",
      "d_loss 0.5766946077346802\n",
      "epoch 206\n",
      "d_loss 0.6699846386909485\n",
      "epoch 207\n",
      "d_loss 0.7354919910430908\n",
      "epoch 208\n",
      "d_loss 0.7384235858917236\n",
      "epoch 209\n",
      "d_loss 0.7270553112030029\n",
      "epoch 210\n",
      "d_loss 0.6661403179168701\n",
      "epoch 211\n",
      "d_loss 0.7011687755584717\n",
      "epoch 212\n",
      "d_loss 0.7420871257781982\n",
      "epoch 213\n",
      "d_loss 0.7082823514938354\n",
      "epoch 214\n",
      "d_loss 0.6922920346260071\n",
      "epoch 215\n",
      "d_loss 0.7106485366821289\n",
      "epoch 216\n",
      "d_loss 0.5815272331237793\n",
      "epoch 217\n",
      "d_loss 0.7121449708938599\n",
      "epoch 218\n",
      "d_loss 0.6287431716918945\n",
      "epoch 219\n",
      "d_loss 0.7084530591964722\n",
      "epoch 220\n",
      "d_loss 0.6680392026901245\n",
      "epoch 221\n",
      "d_loss 0.7120029926300049\n",
      "epoch 222\n",
      "d_loss 0.7615692615509033\n",
      "epoch 223\n",
      "d_loss 0.6938669681549072\n",
      "epoch 224\n",
      "d_loss 0.6115517616271973\n",
      "epoch 225\n",
      "d_loss 0.6723997592926025\n",
      "epoch 226\n",
      "d_loss 0.8218567371368408\n",
      "epoch 227\n",
      "d_loss 0.7365776896476746\n",
      "epoch 228\n",
      "d_loss 0.6843228936195374\n",
      "epoch 229\n",
      "d_loss 0.6596057415008545\n",
      "epoch 230\n",
      "d_loss 0.7098861336708069\n",
      "epoch 231\n",
      "d_loss 0.630109429359436\n",
      "epoch 232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_loss 0.7112106084823608\n",
      "epoch 233\n",
      "d_loss 0.8053199648857117\n",
      "epoch 234\n",
      "d_loss 0.7420376539230347\n",
      "epoch 235\n",
      "d_loss 0.7264261245727539\n",
      "epoch 236\n",
      "d_loss 0.560847282409668\n",
      "epoch 237\n",
      "d_loss 0.6523900628089905\n",
      "epoch 238\n",
      "d_loss 0.739308774471283\n",
      "epoch 239\n",
      "d_loss 0.6958868503570557\n",
      "epoch 240\n",
      "d_loss 0.7069966793060303\n",
      "epoch 241\n",
      "d_loss 0.7104225158691406\n",
      "epoch 242\n",
      "d_loss 0.7108728885650635\n",
      "epoch 243\n",
      "d_loss 0.7106461524963379\n",
      "epoch 244\n",
      "d_loss 0.6207306385040283\n",
      "epoch 245\n",
      "d_loss 0.721518337726593\n",
      "epoch 246\n",
      "d_loss 0.7341879606246948\n",
      "epoch 247\n",
      "d_loss 0.7112916707992554\n",
      "epoch 248\n",
      "d_loss 0.7482991218566895\n",
      "epoch 249\n",
      "d_loss 0.5417584180831909\n",
      "epoch 250\n",
      "d_loss 0.6167834997177124\n",
      "epoch 251\n",
      "d_loss 0.719059944152832\n",
      "epoch 252\n",
      "d_loss 0.7058786153793335\n",
      "epoch 253\n",
      "d_loss 0.7996840476989746\n",
      "epoch 254\n",
      "d_loss 0.7102718949317932\n",
      "epoch 255\n",
      "d_loss 0.7246204614639282\n",
      "epoch 256\n",
      "d_loss 0.7177793979644775\n",
      "epoch 257\n",
      "d_loss 0.6753963232040405\n",
      "epoch 258\n",
      "d_loss 0.7149922847747803\n",
      "epoch 259\n",
      "d_loss 0.7340238094329834\n",
      "epoch 260\n",
      "d_loss 0.7543838024139404\n",
      "epoch 261\n",
      "d_loss 0.7132909297943115\n",
      "epoch 262\n",
      "d_loss 0.7203167676925659\n",
      "epoch 263\n",
      "d_loss 0.7182822823524475\n",
      "epoch 264\n",
      "d_loss 0.6788392066955566\n",
      "epoch 265\n",
      "d_loss 0.693313479423523\n",
      "epoch 266\n",
      "d_loss 0.7048077583312988\n",
      "epoch 267\n",
      "d_loss 0.6669038534164429\n",
      "epoch 268\n",
      "d_loss 0.6119322180747986\n",
      "epoch 269\n",
      "d_loss 0.6968064308166504\n",
      "epoch 270\n",
      "d_loss 0.538418173789978\n",
      "epoch 271\n",
      "d_loss 0.6822196245193481\n",
      "epoch 272\n",
      "d_loss 0.7219982147216797\n",
      "epoch 273\n",
      "d_loss 0.6985016465187073\n",
      "epoch 274\n",
      "d_loss 0.7115765810012817\n",
      "epoch 275\n",
      "d_loss 0.6186590194702148\n",
      "epoch 276\n",
      "d_loss 0.5924946069717407\n",
      "epoch 277\n",
      "d_loss 0.7843922972679138\n",
      "epoch 278\n",
      "d_loss 0.7191463112831116\n",
      "epoch 279\n",
      "d_loss 0.7130934596061707\n",
      "epoch 280\n",
      "d_loss 0.711677074432373\n",
      "epoch 281\n",
      "d_loss 0.6894133687019348\n",
      "epoch 282\n",
      "d_loss 0.7349509000778198\n",
      "epoch 283\n",
      "d_loss 0.6970387697219849\n",
      "epoch 284\n",
      "d_loss 0.709681510925293\n",
      "epoch 285\n",
      "d_loss 0.7111903429031372\n",
      "epoch 286\n",
      "d_loss 0.6435607075691223\n",
      "epoch 287\n",
      "d_loss 0.6848955750465393\n",
      "epoch 288\n",
      "d_loss 0.6823762655258179\n",
      "epoch 289\n",
      "d_loss 0.7477251291275024\n",
      "epoch 290\n",
      "d_loss 0.6588406562805176\n",
      "epoch 291\n",
      "d_loss 0.6909586191177368\n",
      "epoch 292\n",
      "d_loss 0.6404410600662231\n",
      "epoch 293\n",
      "d_loss 0.6997154951095581\n",
      "epoch 294\n",
      "d_loss 0.680766224861145\n",
      "epoch 295\n",
      "d_loss 0.7084628343582153\n",
      "epoch 296\n",
      "d_loss 0.7443442344665527\n",
      "epoch 297\n",
      "d_loss 0.7014737129211426\n",
      "epoch 298\n",
      "d_loss 0.7117687463760376\n",
      "epoch 299\n",
      "d_loss 0.6789752244949341\n"
     ]
    }
   ],
   "source": [
    "for e in range(300):\n",
    "    print('epoch', e)\n",
    "    data = gen.flow_from_directory().__next__()\n",
    "    X_low = data[0]\n",
    "    X_high = data[1]\n",
    "    srgan.train(X_low, X_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_low = ((cv2.imread(test_low_path) - 127.5) / 127.5)[np.newaxis, :, :, :]\n",
    "test_img_high = ((cv2.imread(test_high_path)- 127.5) / 127.5)[np.newaxis, :, :, :]\n",
    "\n",
    "test_img_sr = srgan.generator.predict(test_img_low)\n",
    "test_img_sr_int = ((test_img_sr * 127.5) + 127.5).astype('u1')[0]\n",
    "cv2.imwrite(test_out_path, test_img_sr_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
