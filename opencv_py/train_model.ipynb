{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from srgan import SRGAN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot create group in read-only mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-374b65a68e12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvgg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'vgg16_notop.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msrgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSRGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m270\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1080\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1920\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\git\\practice\\opencv_py\\srgan.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vgg_path, input_shape, tgt_shape)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdics_combined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_disc_combined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\git\\practice\\opencv_py\\srgan.py\u001b[0m in \u001b[0;36mbuild_vgg\u001b[1;34m(self, vgg_path, l)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_vgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mvgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryoji\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryoji\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryoji\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[1;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryoji\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot create group in read-only mode.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot create group in read-only mode."
     ]
    }
   ],
   "source": [
    "vgg_path = 'vgg16_notop.h5'\n",
    "srgan = SRGAN(vgg_path, input_shape=(270, 480, 3), tgt_shape=(1080, 1920, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gan_layers import gan_network\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'train/240p/'\n",
    "tgt_dir = 'train/720p/'\n",
    "img_list = os.listdir(input_dir)\n",
    "assert img_list == os.listdir(tgt_dir)\n",
    "\n",
    "input_path = input_dir + img_list[0]\n",
    "input_shape_temp = np.array(Image.open(input_path)).shape\n",
    "\n",
    "tgt_path = tgt_dir + img_list[0]\n",
    "tgt_shape_temp = np.array(Image.open(tgt_path)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Dense\n",
    "from keras.layers import Flatten, Reshape, Activation, Concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class UNET():\n",
    "    def __init__(self, input_shape=(240, 426, 3), tgt_shape=(720, 1278, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.tgt_shape = tgt_shape\n",
    "\n",
    "        self.gen_net = []\n",
    "        self.dis_net = []\n",
    "        self.res_net = []\n",
    "\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.combined = self.build_combined()\n",
    "        self.optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "        # self.combined.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        # self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "    def build_generator(self, filters=64):\n",
    "        input_layer = Input(shape = self.input_shape)\n",
    "        layers = [input_layer]\n",
    "\n",
    "        # Down 1\n",
    "        layer_name = 'GD0'\n",
    "        self.gen_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv', activation='relu')) #0, 1\n",
    "        self.gen_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_res', activation='relu')) #1, 2\n",
    "        self.gen_net.append(MaxPooling2D(name=layer_name+'_pool')) #2, 3\n",
    "        filters *= 2\n",
    "    \n",
    "        # Down 2\n",
    "        layer_name = 'GD1'\n",
    "        self.gen_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv', activation='relu')) #3, 4\n",
    "        self.gen_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_res', activation='relu')) #4, 5\n",
    "        filters *= 2\n",
    "\n",
    "        # Up 1\n",
    "        layer_name = 'GU0'\n",
    "        filter = int(filters / 2)\n",
    "        self.gen_net.append(UpSampling2D(name=layer_name+'_upsamp')) #5\n",
    "        self.gen_net.append(Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")) #6\n",
    "        ## concat res\n",
    "        self.gen_net.append(Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')) #7    \n",
    "        self.gen_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')) #8\n",
    "    \n",
    "        # Up 2\n",
    "        filter = int(filters / 2)\n",
    "        layer_name = 'GU1'\n",
    "        self.gen_net.append(UpSampling2D(size=(3,3), name=layer_name+'_upsamp')) #9\n",
    "        self.gen_net.append(Conv2D(filters=1, kernel_size=(3, 3), padding='same', name='GoutR', activation=\"sigmoid\")) #10\n",
    "        self.gen_net.append(Conv2D(filters=1, kernel_size=(3, 3), padding='same', name='GoutG', activation=\"sigmoid\")) #11\n",
    "        self.gen_net.append(Conv2D(filters=1, kernel_size=(3, 3), padding='same', name='GoutB', activation=\"sigmoid\")) #12\n",
    "        \n",
    "        for i, l in enumerate(self.gen_net[:7]):\n",
    "            layers.append(l(layers[i]))\n",
    "\n",
    "        layers.append(Concatenate(axis=3)([layers[2], layers[-1]]))\n",
    "        \n",
    "        for i, l in enumerate(self.gen_net[7:10]):\n",
    "            layers.append(l(layers[i+7]))\n",
    "\n",
    "        layers.append(self.gen_net[10](layers[-1]))\n",
    "        layers.append(self.gen_net[11](layers[-2]))\n",
    "        layers.append(self.gen_net[12](layers[-3]))\n",
    "\n",
    "        layers.append(Concatenate(axis=3)([layers[-3], layers[-2], layers[-1]]))\n",
    "\n",
    "        return Model(layers[0], layers[-1])\n",
    "\n",
    "    def build_discriminator(self, filters=16):\n",
    "        input_layer = Input(shape=self.tgt_shape)\n",
    "        layers = [input_layer]\n",
    "        # Down 1\n",
    "        layer_name = 'DD0'\n",
    "        self.dis_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv0', activation='relu')) #0, 1\n",
    "        self.dis_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv1', activation='relu')) #1, 2\n",
    "        self.dis_net.append(MaxPooling2D(name=layer_name+'_pool')) #2, 3\n",
    "        filters *= 2\n",
    "    \n",
    "        # Down 2\n",
    "        layer_name = 'DD1'\n",
    "        self.dis_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv0', activation='relu')) #3, 4\n",
    "        self.dis_net.append(Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv1', activation='relu')) #4, 5\n",
    "        \n",
    "        for i, l in enumerate(self.dis_net):\n",
    "            layers.append(l(layers[i]))\n",
    "\n",
    "        model = Model(layers[0], layers[-1])\n",
    "        return model\n",
    "\n",
    "    def set_combine_trainable(self):\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = True\n",
    "\n",
    "    def unset_combine_trainable(self):\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = False\n",
    "\n",
    "    def build_combined(self):\n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        layers = [input_layer]\n",
    "\n",
    "        self.num_gen = len(self.generator.layers)\n",
    "        self.num_disc = len(self.discriminator.layers)\n",
    "\n",
    "        for i, l in enumerate(self.gen_net[:7]):\n",
    "            layers.append(l(layers[i]))\n",
    "\n",
    "        layers.append(Concatenate(axis=3)([layers[2], layers[-1]]))\n",
    "        \n",
    "        for i, l in enumerate(self.gen_net[7:10]):\n",
    "            layers.append(l(layers[i+7]))\n",
    "\n",
    "        layers.append(self.gen_net[10](layers[-1]))\n",
    "        layers.append(self.gen_net[11](layers[-2]))\n",
    "        layers.append(self.gen_net[12](layers[-3]))\n",
    "\n",
    "        layers.append(Concatenate(axis=3)([layers[-3], layers[-2], layers[-1]]))\n",
    "\n",
    "        temp_num = len(layers)\n",
    "\n",
    "        for i, l in enumerate(self.dis_net):\n",
    "            layers.append(l(layers[i+temp_num-1]))\n",
    "\n",
    "        return Model(layers[0], layers[-1])\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128):\n",
    "        half_batch = int(batch_size / 2)\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "            noise = np.random.uniform(-1, 1, (half_batch, 1, self.z_dim))\n",
    "\n",
    "            # -----------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            self.set_combine_trainable()\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            self.unset_combine_trainable()\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, 1, self.z_dim))\n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            print(\"Epoch:%d\" % epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET().combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 240, 426, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GD0_conv (Conv2D)               (None, 240, 426, 64) 1792        input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "GD0_res (Conv2D)                (None, 240, 426, 64) 36928       GD0_conv[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "GD0_pool (MaxPooling2D)         (None, 120, 213, 64) 0           GD0_res[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "GD1_conv (Conv2D)               (None, 120, 213, 128 73856       GD0_pool[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "GD1_res (Conv2D)                (None, 120, 213, 128 147584      GD1_conv[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "GU0_upsamp (UpSampling2D)       (None, 240, 426, 128 0           GD1_res[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "GU0_upconv (Conv2D)             (None, 240, 426, 256 131328      GU0_upsamp[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GU0_conv1 (Conv2D)              (None, 240, 426, 256 590080      GU0_upconv[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GU1_upsamp (UpSampling2D)       (None, 720, 1278, 25 0           GU0_conv1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "GoutR (Conv2D)                  (None, 720, 1278, 1) 2305        GU1_upsamp[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GoutG (Conv2D)                  (None, 720, 1278, 1) 2305        GU1_upsamp[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GoutB (Conv2D)                  (None, 720, 1278, 1) 2305        GU1_upsamp[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 720, 1278, 3) 0           GoutR[1][0]                      \n",
      "                                                                 GoutG[1][0]                      \n",
      "                                                                 GoutB[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "DD0_conv0 (Conv2D)              (None, 720, 1278, 16 448         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DD0_conv1 (Conv2D)              (None, 720, 1278, 16 2320        DD0_conv0[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "DD0_pool (MaxPooling2D)         (None, 360, 639, 16) 0           DD0_conv1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "DD1_conv0 (Conv2D)              (None, 360, 639, 32) 4640        DD0_pool[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DD1_conv1 (Conv2D)              (None, 360, 639, 32) 9248        DD1_conv0[1][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,005,139\n",
      "Trainable params: 1,005,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Dense\n",
    "from keras.layers import Flatten, Reshape, Activation, Concatenate, Dropout, BatchNormalization\n",
    "\n",
    "class UNET():\n",
    "    def __init__(self, input_shape=(240, 426, 3), tgt_shape=(720, 1278, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.tgt_shape = tgt_shape\n",
    "\n",
    "    def down(self, input_layer, filters, layer_name, pool=True):\n",
    "        conv = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv', activation='relu')(input_layer)\n",
    "        res = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_res', activation='relu')(conv)\n",
    "        if pool:\n",
    "            max_pool = MaxPooling2D(name=layer_name+'_pool',)(res)\n",
    "            return max_pool, res\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def up_res(self, input_layer, residual, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        concat = Concatenate(axis=3)([residual, upconv])\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(concat)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "    \n",
    "    def up_only(self, input_layer, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(upconv)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "\n",
    "    def unet(self, num_filter=64):\n",
    "        input_layer = Input(shape = self.input_shape)\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 64\n",
    "        down1, res1 = self.down(input_layer, num_filter, layer_name='D1')\n",
    "        residuals.append(res1)\n",
    "        num_filter *= 2\n",
    "\n",
    "        # Down 2, 8\n",
    "        down2 = self.down(down1, num_filter, layer_name='D2', pool=False)\n",
    "\n",
    "        # Up 1, 128\n",
    "        num_filter /= 2\n",
    "        up1 = self.up_res(down2, residual=residuals[-1], layer_name='U1', filters=num_filter)\n",
    "\n",
    "        # Up 2, 64\n",
    "        num_filter /= 2\n",
    "        up2 = UpSampling2D(size=(3,3), name='U2_upsamp')(up1)\n",
    "        outR = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outR')(up2)\n",
    "        outG = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outG')(up2)\n",
    "        outB = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outB')(up2)\n",
    "        out  = Concatenate(axis=3)([outR, outG, outB])\n",
    "        \n",
    "        model = Model(input_layer, out)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET().unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 240, 426, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "D1_conv (Conv2D)                (None, 240, 426, 64) 1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D1_res (Conv2D)                 (None, 240, 426, 64) 36928       D1_conv[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D1_pool (MaxPooling2D)          (None, 120, 213, 64) 0           D1_res[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "D2_conv (Conv2D)                (None, 120, 213, 128 73856       D1_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D2_res (Conv2D)                 (None, 120, 213, 128 147584      D2_conv[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "U1_upsamp (UpSampling2D)        (None, 240, 426, 128 0           D2_res[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "U1_upconv (Conv2D)              (None, 240, 426, 64) 32832       U1_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 240, 426, 128 0           D1_res[0][0]                     \n",
      "                                                                 U1_upconv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "U1_conv1 (Conv2D)               (None, 240, 426, 64) 73792       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "U1_conv2 (Conv2D)               (None, 240, 426, 64) 36928       U1_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "U2_upsamp (UpSampling2D)        (None, 720, 1278, 64 0           U1_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "outR (Conv2D)                   (None, 720, 1278, 1) 65          U2_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "outG (Conv2D)                   (None, 720, 1278, 1) 65          U2_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "outB (Conv2D)                   (None, 720, 1278, 1) 65          U2_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 720, 1278, 3) 0           outR[0][0]                       \n",
      "                                                                 outG[0][0]                       \n",
      "                                                                 outB[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 403,907\n",
      "Trainable params: 403,907\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x240a5f26dd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(object):\n",
    "    def __init__(self, input_dir, tgt_dir):\n",
    "        self.input_dir = input_dir\n",
    "        self.tgt_dir = tgt_dir\n",
    "        self.img_list = os.listdir(input_dir)\n",
    "        assert self.img_list == os.listdir(tgt_dir)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "    def flow_from_directory(self, batch_size=16):\n",
    "        train_imges = random.sample(self.img_list, batch_size)\n",
    "        while True:\n",
    "            for img in train_imges:\n",
    "                input_path = input_dir + img\n",
    "                tgt_path = tgt_dir + img\n",
    "\n",
    "                X = (np.array(Image.open(input_path)) - 127.5) / 127.5\n",
    "                Y = (np.array(Image.open(tgt_path)) - 127.5) / 127.5\n",
    "\n",
    "                X_list.append(X.reshape([1, X.shape[0], X.shape[1], X.shape[2]]))\n",
    "                Y_list.append(Y.reshape([1, Y.shape[0], Y.shape[1], Y.shape[2]]))\n",
    "    \n",
    "            inputs = np.vstack(X_list)\n",
    "            targets = np.vstack(Y_list)\n",
    "\n",
    "            yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Dense\n",
    "from keras.layers import Flatten, Reshape, Activation, Concatenate, Dropout, BatchNormalization\n",
    "\n",
    "class UNET():\n",
    "    def __init__(self, input_shape=(240, 426, 3), tgt_shape=(720, 1278, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.tgt_shape = tgt_shape\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.combined = self.build_combined()\n",
    "        self.optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "\n",
    "    def down(self, input_layer, filters, layer_name, pool=True):\n",
    "        conv = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv', activation='relu')(input_layer)\n",
    "        res = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_res', activation='relu')(conv)\n",
    "        if pool:\n",
    "            max_pool = MaxPooling2D(name=layer_name+'_pool',)(res)\n",
    "            return max_pool, res\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def up_res(self, input_layer, residual, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        concat = Concatenate(axis=3)([residual, upconv])\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(concat)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "    \n",
    "    def up_only(self, input_layer, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(upconv)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "\n",
    "    def build_generator(self, num_filter=64):\n",
    "        input_layer = Input(shape = self.input_shape)\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 64\n",
    "        down1, res1 = self.down(input_layer, num_filter, layer_name='D1')\n",
    "        residuals.append(res1)\n",
    "        num_filter *= 2\n",
    "\n",
    "        # Down 2, 8\n",
    "        down2 = self.down(down1, num_filter, layer_name='D2', pool=False)\n",
    "\n",
    "        # Up 1, 128\n",
    "        num_filter /= 2\n",
    "        up1 = self.up_res(down2, residual=residuals[-1], layer_name='U1', filters=num_filter)\n",
    "\n",
    "        # Up 2, 64\n",
    "        num_filter /= 2\n",
    "        up2 = UpSampling2D(size=(3,3), name='U2_upsamp')(up1)\n",
    "        outR = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outR')(up2)\n",
    "        outG = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outG')(up2)\n",
    "        outB = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outB')(up2)\n",
    "        self.out  = Concatenate(axis=3)([outR, outG, outB])\n",
    "        \n",
    "        model = Model(input_layer, out)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self, num_filter=16):\n",
    "        # Down 1\n",
    "        down1, res1 = self.down(self.out, num_filter, layer_name='D1')\n",
    "        num_filter *= 2\n",
    "\n",
    "        # Down 2\n",
    "        down2, res2 = self.down(down1, num_filter, layer_name='D2')\n",
    "        num_filter *= 2\n",
    "\n",
    "        model = Model(input_layer, out)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def set_combine_trainable(self):\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = True\n",
    "\n",
    "    def unset_combine_trainable(self):\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = False\n",
    "\n",
    "    def build_combined(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        tensors = [inputs]\n",
    "\n",
    "        self.num_gen = len(self.generator.layers)\n",
    "        self.num_disc = len(self.discriminator.layers)\n",
    "\n",
    "        for i, l in enumerate(self.generator.layers):\n",
    "            tensors.append(l(tensors[i]))\n",
    "\n",
    "        for i, l in enumerate(self.discriminator.layers):\n",
    "            tensors.append(l(tensors[i+self.num_gen]))\n",
    "\n",
    "        return Model(tensors[0], tensors[-1])\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128):\n",
    "        half_batch = int(batch_size / 2)\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "            noise = np.random.uniform(-1, 1, (half_batch, 1, self.z_dim))\n",
    "\n",
    "            # -----------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            self.set_combine_trainable()\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            self.unset_combine_trainable()\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, 1, self.z_dim))\n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            print(\"Epoch:%d\" % epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
