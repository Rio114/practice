{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gan_layers import gan_network\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'train/240p/'\n",
    "tgt_dir = 'train/720p/'\n",
    "img_list = os.listdir(input_dir)\n",
    "assert img_list == os.listdir(tgt_dir)\n",
    "\n",
    "input_path = input_dir + img_list[0]\n",
    "input_shape_temp = np.array(Image.open(input_path)).shape\n",
    "\n",
    "tgt_path = tgt_dir + img_list[0]\n",
    "tgt_shape_temp = np.array(Image.open(tgt_path)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from layer import UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Dense\n",
    "from keras.layers import Flatten, Reshape, Activation, Concatenate, Dropout, BatchNormalization\n",
    "\n",
    "class UNET():\n",
    "    def __init__(self, input_shape=(240, 426, 3), tgt_shape=(720, 1278, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.tgt_shape = tgt_shape\n",
    "\n",
    "    def down(self, input_layer, filters, layer_name, pool=True):\n",
    "        conv = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv', activation='relu')(input_layer)\n",
    "        res = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_res', activation='relu')(conv)\n",
    "        if pool:\n",
    "            max_pool = MaxPooling2D(name=layer_name+'_pool',)(res)\n",
    "            return max_pool, res\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def up_res(self, input_layer, residual, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        concat = Concatenate(axis=3)([residual, upconv])\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(concat)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "    \n",
    "    def up_only(self, input_layer, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(upconv)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "\n",
    "    def unet(self, num_filter=64):\n",
    "        input_layer = Input(shape = self.input_shape)\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 64\n",
    "        down1, res1 = self.down(input_layer, num_filter, layer_name='D1')\n",
    "        residuals.append(res1)\n",
    "        num_filter *= 2\n",
    "\n",
    "        # Down 2, 8\n",
    "        down2 = self.down(down1, num_filter, layer_name='D2', pool=False)\n",
    "\n",
    "        # Up 1, 128\n",
    "        num_filter /= 2\n",
    "        up1 = self.up_res(down2, residual=residuals[-1], layer_name='U1', filters=num_filter)\n",
    "\n",
    "        # Up 2, 64\n",
    "        num_filter /= 2\n",
    "        up2 = UpSampling2D(size=(3,3), name='U2_upsamp')(up1)\n",
    "        outR = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outR')(up2)\n",
    "        outG = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outG')(up2)\n",
    "        outB = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outB')(up2)\n",
    "        out  = Concatenate(axis=3)([outR, outG, outB])\n",
    "        \n",
    "        model = Model(input_layer, out)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET().unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 240, 426, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "D1_conv (Conv2D)                (None, 240, 426, 64) 1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D1_res (Conv2D)                 (None, 240, 426, 64) 36928       D1_conv[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D1_pool (MaxPooling2D)          (None, 120, 213, 64) 0           D1_res[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "D2_conv (Conv2D)                (None, 120, 213, 128 73856       D1_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D2_res (Conv2D)                 (None, 120, 213, 128 147584      D2_conv[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "U1_upsamp (UpSampling2D)        (None, 240, 426, 128 0           D2_res[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "U1_upconv (Conv2D)              (None, 240, 426, 64) 32832       U1_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 240, 426, 128 0           D1_res[0][0]                     \n",
      "                                                                 U1_upconv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "U1_conv1 (Conv2D)               (None, 240, 426, 64) 73792       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "U1_conv2 (Conv2D)               (None, 240, 426, 64) 36928       U1_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "U2_upsamp (UpSampling2D)        (None, 720, 1278, 64 0           U1_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "outR (Conv2D)                   (None, 720, 1278, 1) 65          U2_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "outG (Conv2D)                   (None, 720, 1278, 1) 65          U2_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "outB (Conv2D)                   (None, 720, 1278, 1) 65          U2_upsamp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 720, 1278, 3) 0           outR[0][0]                       \n",
      "                                                                 outG[0][0]                       \n",
      "                                                                 outB[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 403,907\n",
      "Trainable params: 403,907\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x240a5f26dd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(object):\n",
    "    def __init__(self, input_dir, tgt_dir):\n",
    "        self.input_dir = input_dir\n",
    "        self.tgt_dir = tgt_dir\n",
    "        self.img_list = os.listdir(input_dir)\n",
    "        assert self.img_list == os.listdir(tgt_dir)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "    def flow_from_directory(self, batch_size=16):\n",
    "        train_imges = random.sample(self.img_list, batch_size)\n",
    "        while True:\n",
    "            for img in train_imges:\n",
    "                input_path = input_dir + img\n",
    "                tgt_path = tgt_dir + img\n",
    "\n",
    "                X = (np.array(Image.open(input_path)) - 127.5) / 127.5\n",
    "                Y = (np.array(Image.open(tgt_path)) - 127.5) / 127.5\n",
    "\n",
    "                X_list.append(X.reshape([1, X.shape[0], X.shape[1], X.shape[2]]))\n",
    "                Y_list.append(Y.reshape([1, Y.shape[0], Y.shape[1], Y.shape[2]]))\n",
    "    \n",
    "            inputs = np.vstack(X_list)\n",
    "            targets = np.vstack(Y_list)\n",
    "\n",
    "            yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Dense\n",
    "from keras.layers import Flatten, Reshape, Activation, Concatenate, Dropout, BatchNormalization\n",
    "\n",
    "class UNET():\n",
    "    def __init__(self, input_shape=(240, 426, 3), tgt_shape=(720, 1278, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.tgt_shape = tgt_shape\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.combined = self.build_combined()\n",
    "        self.optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "\n",
    "    def down(self, input_layer, filters, layer_name, pool=True):\n",
    "        conv = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv', activation='relu')(input_layer)\n",
    "        res = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_res', activation='relu')(conv)\n",
    "        if pool:\n",
    "            max_pool = MaxPooling2D(name=layer_name+'_pool',)(res)\n",
    "            return max_pool, res\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def up_res(self, input_layer, residual, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        concat = Concatenate(axis=3)([residual, upconv])\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(concat)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "    \n",
    "    def up_only(self, input_layer, filters, layer_name):\n",
    "        filters= int(filters)\n",
    "        upsample = UpSampling2D(name=layer_name+'_upsamp')(input_layer)\n",
    "        upconv = Conv2D(filters, kernel_size=(2, 2), name=layer_name+'_upconv', padding=\"same\")(upsample)\n",
    "        conv1 = Conv2D(filters, (3, 3), padding='same',  name=layer_name+'_conv1', activation='relu')(upconv)    \n",
    "        conv2 = Conv2D(filters, (3, 3), padding='same', name=layer_name+'_conv2', activation='relu')(conv1)\n",
    "        return conv2\n",
    "\n",
    "    def build_generator(self, num_filter=64):\n",
    "        input_layer = Input(shape = self.input_shape)\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 64\n",
    "        down1, res1 = self.down(input_layer, num_filter, layer_name='D1')\n",
    "        residuals.append(res1)\n",
    "        num_filter *= 2\n",
    "\n",
    "        # Down 2, 8\n",
    "        down2 = self.down(down1, num_filter, layer_name='D2', pool=False)\n",
    "\n",
    "        # Up 1, 128\n",
    "        num_filter /= 2\n",
    "        up1 = self.up_res(down2, residual=residuals[-1], layer_name='U1', filters=num_filter)\n",
    "\n",
    "        # Up 2, 64\n",
    "        num_filter /= 2\n",
    "        up2 = UpSampling2D(size=(3,3), name='U2_upsamp')(up1)\n",
    "        outR = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outR')(up2)\n",
    "        outG = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outG')(up2)\n",
    "        outB = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\", name='outB')(up2)\n",
    "        self.out  = Concatenate(axis=3)([outR, outG, outB])\n",
    "        \n",
    "        model = Model(input_layer, out)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self, num_filter=16):\n",
    "        # Down 1\n",
    "        down1, res1 = self.down(self.out, num_filter, layer_name='D1')\n",
    "        num_filter *= 2\n",
    "\n",
    "        # Down 2\n",
    "        down2, res2 = self.down(down1, num_filter, layer_name='D2')\n",
    "        num_filter *= 2\n",
    "\n",
    "        model = Model(input_layer, out)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def set_combine_trainable(self):\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = True\n",
    "\n",
    "    def unset_combine_trainable(self):\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = False\n",
    "\n",
    "    def build_combined(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        tensors = [inputs]\n",
    "\n",
    "        self.num_gen = len(self.generator.layers)\n",
    "        self.num_disc = len(self.discriminator.layers)\n",
    "\n",
    "        for i, l in enumerate(self.generator.layers):\n",
    "            tensors.append(l(tensors[i]))\n",
    "\n",
    "        for i, l in enumerate(self.discriminator.layers):\n",
    "            tensors.append(l(tensors[i+self.num_gen]))\n",
    "\n",
    "        return Model(tensors[0], tensors[-1])\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128):\n",
    "        half_batch = int(batch_size / 2)\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "            noise = np.random.uniform(-1, 1, (half_batch, 1, self.z_dim))\n",
    "\n",
    "            # -----------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            self.set_combine_trainable()\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            self.unset_combine_trainable()\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, 1, self.z_dim))\n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            print(\"Epoch:%d\" % epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
