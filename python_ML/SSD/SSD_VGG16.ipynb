{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssd_vgg16 import SSD_VGG16\n",
    "from ssd_utils import BBoxUtility\n",
    "from gen import Generator\n",
    "from ssd_training import MultiboxLoss\n",
    "from ssd_layer import DefaultBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## difinition of folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '../'\n",
    "CSV_FOLDER = FOLDER + 'csv/'\n",
    "EXT_FOLDER = FOLDER + 'extracted/'\n",
    "EXT_TRUE = EXT_FOLDER + 'face_true/'\n",
    "EXT_FALSE = EXT_FOLDER + 'face_false/'\n",
    "SCR_FOLDER = FOLDER + 'scraped/images_best_titles/'\n",
    "\n",
    "FALSE_FILES = os.listdir(EXT_FALSE)\n",
    "TRUE_FILES = os.listdir(EXT_TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparation for SSD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRUE_FILES) + len(FALSE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(CSV_FOLDER+'ext_face_flg_size.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df_raw[df_raw['flg']==1]\n",
    "df_neg = df_raw[df_raw['flg']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loc(df):\n",
    "    xsize_arr = df['xsize'].values\n",
    "    ysize_arr = df['ysize'].values\n",
    "    x0_arr = df['x0'].values / xsize_arr\n",
    "    x1_arr = df['x1'].values / xsize_arr \n",
    "    y0_arr = df['y0'].values / ysize_arr\n",
    "    y1_arr = df['y1'].values / ysize_arr\n",
    "    locs = np.vstack([y0_arr, x0_arr, y1_arr, x1_arr]).T\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_pos = calc_loc(df_pos)\n",
    "loc_neg = calc_loc(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = np.vstack([loc_pos, loc_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "names = df_pos['name'].values.reshape(-1, 1)\n",
    "label_pos = ohe.fit_transform(names).toarray()\n",
    "\n",
    "# label_pos = np.zeros([loc_pos.shape[0], 1])\n",
    "# label_pos[:, 0] = 1\n",
    "\n",
    "label_bg_pos = np.zeros([label_pos.shape[0], 1])\n",
    "label_pos = np.hstack([label_bg_pos, label_pos])\n",
    "\n",
    "label_neg = np.zeros([loc_neg.shape[0], label_pos.shape[1]])\n",
    "# label_neg[:, 0] = 1\n",
    "\n",
    "\n",
    "print(label_pos.shape)\n",
    "print(label_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.vstack([label_pos, label_neg])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_label_arr = np.hstack([locs, labels])\n",
    "loc_label_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_file_list(df):\n",
    "    fname_list = []\n",
    "    files = df['file_path']\n",
    "    for i, f in enumerate(files):\n",
    "        fname = df['name'].values[i] + '/' + f.split('/')[-1]\n",
    "        fname_list.append(fname)\n",
    "    return fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_list = []\n",
    "fname_list_pos = gen_file_list(df_pos)\n",
    "fname_list_neg = gen_file_list(df_neg)\n",
    "fname_list.extend(fname_list_pos)\n",
    "fname_list.extend(fname_list_neg)\n",
    "len(fname_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "se = pd.Series(fname_list)\n",
    "idx = se.value_counts().index\n",
    "for i in idx:\n",
    "    mask = se == i\n",
    "    gt[i] = loc_label_arr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = gt.keys()\n",
    "num = len(keys)\n",
    "num_train = round(num * 0.9)\n",
    "pickup = random.sample(range(num), num)\n",
    "pickup_train = pickup[:num_train]\n",
    "pickup_val = pickup[num_train:]\n",
    "keys_train = list(np.array(list(keys))[pickup_train])\n",
    "keys_val = list(np.array(list(keys))[pickup_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pickup_train) + len(pickup_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretraining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# vgg16_original = VGG16(include_top=True,\n",
    "#                                weights='imagenet',\n",
    "#                                input_tensor=None, \n",
    "#                                input_shape=None, \n",
    "#                                pooling=None, \n",
    "#                                classes=1000)\n",
    "# vgg16_original.save_weights('vgg16_original.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = label_pos.shape[1]\n",
    "input_shape = (300, 300, 3) # (y, x, c)\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "model_obj = SSD_VGG16(num_classes=NUM_CLASSES, img_size=input_shape, variances=variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_obj.SSD()\n",
    "for L in model.layers[:19]:\n",
    "    L.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_list = model_obj.get_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = input_shape[:2]\n",
    "priors = np.zeros(8).reshape(1,-1)\n",
    "aspects = [1.0, 1.0, 2, 3, 1/2, 1/3]\n",
    "for i in range(len(det_list)):\n",
    "    det_grid = np.array([det_list[i].shape[1].value, det_list[i].shape[2].value])\n",
    "    steps = (img_size / det_grid).astype(np.int)\n",
    "\n",
    "    y_cent_arr = (np.linspace(steps[0]/2, img_size[0]-steps[0]/2, det_grid[0]))\n",
    "    x_cent_arr = (np.linspace(steps[1]/2, img_size[1]-steps[1]/2, det_grid[1]))\n",
    "    y_cent, x_cent = np.meshgrid(y_cent_arr, x_cent_arr)\n",
    "    y_cent = y_cent.reshape(-1,1)\n",
    "    x_cent = x_cent.reshape(-1,1)\n",
    "\n",
    "    y_var = np.ones_like(y_cent).reshape(-1,1) * variances[0]\n",
    "    x_var = np.ones_like(x_cent).reshape(-1,1) * variances[1]\n",
    "    h_var = np.ones_like(y_cent).reshape(-1,1) * variances[2]\n",
    "    w_var = np.ones_like(x_cent).reshape(-1,1) * variances[3]\n",
    "\n",
    "    for asp in aspects:\n",
    "        h_arr = np.ones(det_grid[0]**2).reshape(-1,1) * steps[0] * asp\n",
    "        w_arr = np.ones(det_grid[1]**2).reshape(-1,1) * steps[1] / asp\n",
    "        y_mins  = np.clip(y_cent - h_arr // 2, 0, img_size[0])\n",
    "        x_mins  = np.clip(x_cent - h_arr // 2, 0, img_size[1])\n",
    "        y_maxs  = np.clip(y_cent + h_arr // 2, 0, img_size[0])\n",
    "        x_maxs = np.clip(x_cent + w_arr // 2, 0, img_size[1])\n",
    "        priors_pos = np.hstack([y_mins, x_mins, y_maxs, x_maxs])\n",
    "        priors_var = np.hstack([y_var, x_var, h_var, w_var])\n",
    "        priors_dum = np.hstack([priors_pos, priors_var])\n",
    "        priors = np.vstack([priors, priors_dum])\n",
    "\n",
    "priors = priors[1:]\n",
    "priors[:, 0] = priors[:, 0] / img_size[0]\n",
    "priors[:, 1] = priors[:, 1] / img_size[1]\n",
    "priors[:, 2] = priors[:, 2] / img_size[0]\n",
    "priors[:, 3] = priors[:, 3] / img_size[1]\n",
    "priors.shape #(4*4*6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_util = BBoxUtility(NUM_CLASSES, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "gen = Generator(gt, bbox_util, batch_size, SCR_FOLDER,\n",
    "                keys_train, keys_val,\n",
    "                input_shape, do_crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_lr = 0.01\n",
    "adm = keras.optimizers.Adam(lr=base_lr)\n",
    "model.compile(optimizer=adm,\n",
    "              loss=MultiboxLoss(NUM_CLASSES, alpha=1.0).compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit_generator(gen.generate(True), \n",
    "                              steps_per_epoch=(len(keys_train)//batch_size) // 2, \n",
    "                              verbose=1,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=gen.generate(False),\n",
    "                              validation_steps=(len(keys_val)//batch_size)) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 1693\n",
    "j = 2212\n",
    "img_path = SCR_FOLDER + fname_list[j]\n",
    "img = image.load_img(img_path, target_size=input_shape[:2])\n",
    "img = image.img_to_array(img)\n",
    "x = img.reshape((-1,)+input_shape) / 255\n",
    "y_pred = model.predict(x) \n",
    "# (sample, defaultbox, (4(output: cy, cx, h, w), 2(num_class), 8(default box: ymin, xmin, ymax, xmax, varyc, varxc, varh, varw)))\n",
    "results = bbox_util.detection_out(y_pred, confidence_threshold=0.001)\n",
    "\n",
    "img = image.load_img(img_path)\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "gt_ = gt[fname_list[j]]\n",
    "det_ymin = gt_[:, 0]\n",
    "det_xmin = gt_[:, 1]\n",
    "det_ymax = gt_[:, 2]\n",
    "det_xmax = gt_[:, 3]\n",
    "\n",
    "plt.imshow(img / 255.)\n",
    "currentAxis = plt.gca()\n",
    "for i in range(len(gt_)):\n",
    "    ymin = int(round(det_ymin[i] * img.shape[0]))\n",
    "    xmin = int(round(det_xmin[i] * img.shape[1]))\n",
    "    ymax = int(round(det_ymax[i] * img.shape[0]))\n",
    "    xmax = int(round(det_xmax[i] * img.shape[1]))\n",
    "\n",
    "    coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords, fill=False,  edgecolor='white', linewidth=2))\n",
    "\n",
    "det_label = results[0][:, 0]\n",
    "det_conf = results[0][:, 1]\n",
    "det_ymin = results[0][:, 2]\n",
    "det_xmin = results[0][:, 3]\n",
    "det_ymax = results[0][:, 4]\n",
    "det_xmax = results[0][:, 5]\n",
    "\n",
    "# Get detections with confidence higher than 0.6.\n",
    "top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.007]\n",
    "\n",
    "top_conf = det_conf[top_indices]\n",
    "top_label_indices = det_label[top_indices].tolist()\n",
    "top_ymin = det_ymin[top_indices]\n",
    "top_xmin = det_xmin[top_indices]\n",
    "top_ymax = det_ymax[top_indices]\n",
    "top_xmax = det_xmax[top_indices]\n",
    "\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
    "\n",
    "plt.imshow(img / 255.)\n",
    "currentAxis = plt.gca()\n",
    "\n",
    "for i in range(top_conf.shape[0]):\n",
    "    ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "    xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "    ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "    xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "    score = top_conf[i]\n",
    "    label = int(top_label_indices[i])\n",
    "    display_txt = '{:0.2f}, {}'.format(score, label)\n",
    "    coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "    color = colors[0]\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "#     currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 1693\n",
    "j = 2212\n",
    "img_path = SCR_FOLDER + fname_list[j]\n",
    "img = image.load_img(img_path, target_size=input_shape[:2])\n",
    "img = image.img_to_array(img)\n",
    "x = img.reshape((-1,)+input_shape) / 255\n",
    "y_pred = model.predict(x) \n",
    "# (sample, defaultbox, (4(output: cy, cx, h, w), 2(num_class), 8(default box: ymin, xmin, ymax, xmax, varyc, varxc, varh, varw)))\n",
    "results = bbox_util.detection_out(y_pred, confidence_threshold=0.001)\n",
    "\n",
    "img = image.load_img(img_path)\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "gt_ = gt[fname_list[j]]\n",
    "det_ymin = gt_[:, 0]\n",
    "det_xmin = gt_[:, 1]\n",
    "det_ymax = gt_[:, 2]\n",
    "det_xmax = gt_[:, 3]\n",
    "\n",
    "plt.imshow(img / 255.)\n",
    "currentAxis = plt.gca()\n",
    "for i in range(len(gt_)):\n",
    "    ymin = int(round(det_ymin[i] * img.shape[0]))\n",
    "    xmin = int(round(det_xmin[i] * img.shape[1]))\n",
    "    ymax = int(round(det_ymax[i] * img.shape[0]))\n",
    "    xmax = int(round(det_xmax[i] * img.shape[1]))\n",
    "\n",
    "    coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords, fill=False,  edgecolor='white', linewidth=2))\n",
    "\n",
    "det_label = results[0][:, 0]\n",
    "det_conf = results[0][:, 1]\n",
    "det_ymin = results[0][:, 2]\n",
    "det_xmin = results[0][:, 3]\n",
    "det_ymax = results[0][:, 4]\n",
    "det_xmax = results[0][:, 5]\n",
    "\n",
    "# Get detections with confidence higher than 0.6.\n",
    "top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.006]\n",
    "\n",
    "top_conf = det_conf[top_indices]\n",
    "top_label_indices = det_label[top_indices].tolist()\n",
    "top_ymin = det_ymin[top_indices]\n",
    "top_xmin = det_xmin[top_indices]\n",
    "top_ymax = det_ymax[top_indices]\n",
    "top_xmax = det_xmax[top_indices]\n",
    "\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
    "\n",
    "plt.imshow(img / 255.)\n",
    "currentAxis = plt.gca()\n",
    "\n",
    "for i in range(top_conf.shape[0]):\n",
    "    ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "    xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "    ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "    xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "    score = top_conf[i]\n",
    "    label = int(top_label_indices[i])\n",
    "    display_txt = '{:0.2f}, {}'.format(score, label)\n",
    "    coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "    color = colors[0]\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "#     currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
