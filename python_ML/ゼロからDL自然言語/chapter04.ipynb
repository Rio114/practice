{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "import collections\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "#         self.grads = [tf.Variable(tf.zeros_like(W))]\n",
    "        self.grads_np = [np.zeros_like(W.numpy())]\n",
    "        self.grads = [tf.Variable(self.grads_np[0])]\n",
    "    \n",
    "        self.idx = None\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W.numpy()[idx, :]\n",
    "        return tf.Variable(out)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "#         for word_id in self.idx:\n",
    "#             self.grads[0].assign(self.grads[0] + tf.slice(dout, [word_id, 0], [1, dout.shape[1]]))\n",
    "        self.grads_np[0][self.idx, :] += dout.numpy()\n",
    "        self.grads[0].assign(self.grads[0] + tf.constant(self.grads_np[0]))\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, h, idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = tf.math.reduce_sum(target_W * h, axis=1)\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = tf.reshape(dout, (dout.shape[0], 1))\n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramSampler:\n",
    "    def __init__(self, corpus, power, sample_size):\n",
    "        self.sample_size = sample_size\n",
    "        self.vocab_size = None\n",
    "        self.word_p = None\n",
    "\n",
    "        self.counts = collections.Counter(corpus.numpy())\n",
    "        vocab_size = len(self.counts)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.word_p = np.zeros(vocab_size)\n",
    "        for i in range(vocab_size):\n",
    "            self.word_p[i] = self.counts[i]\n",
    "\n",
    "        self.word_p = np.power(self.word_p, power)\n",
    "        self.word_p /= np.sum(self.word_p)\n",
    "\n",
    "    def get_negative_sample(self, target):\n",
    "        batch_size = target.shape[0]\n",
    "        if not GPU:\n",
    "            negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                p = self.word_p.copy()\n",
    "                target_idx = target[i]\n",
    "                p[target_idx] = 0\n",
    "                p /= p.sum()\n",
    "                negative_sample[i, :] = np.random.choice(list(self.counts.keys()), size=self.sample_size, replace=False, p=p)\n",
    "        else:\n",
    "            # GPU(cupy）で計算するときは、速度を優先\n",
    "            # 負例にターゲットが含まれるケースがある\n",
    "            negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size),\n",
    "                                               replace=True, p=self.word_p)\n",
    "\n",
    "        return negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power=0.75, sample_size=5):\n",
    "        self.sample_size = sample_size\n",
    "        self.samplar = UnigramSampler(corpus, power, sample_size)\n",
    "        self.loss_layer = [SigmoidWithLoss() for _ in range(sample_size + 1)]\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]\n",
    "        \n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, h, target):\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.samplar.get_negative_sample(target)\n",
    "\n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = tf.ones(batch_size, dtype='int32')\n",
    "        loss = self.loss_layer[0].forward(score, correct_label)\n",
    "\n",
    "        negative_label = tf.zeros(batch_size, dtype='int32')\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:, 1]\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_layer[1 + i].forward(score, negative_label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for l0, l1 in zip(self.loss_layer, self.embed_dot_layers):\n",
    "            dscore = l0.backward(dout)\n",
    "            dh += l1.backward(dscore)\n",
    "\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 重みの初期化\n",
    "        W_in = tf.Variable(tf.random.normal((V, H), mean=0.0, stddev=0.01, dtype='float'))\n",
    "        W_out = tf.Variable(tf.random.normal((V, H), mean=0.0, stddev=0.01, dtype='float'))\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embeddingレイヤを使用\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # メンバ変数に単語の分散表現を設定\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "from common.optimizer import Adam\n",
    "from common.functions import softmax, cross_entropy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None  # sigmoidの出力\n",
    "        self.t = None  # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = 1 / (1 + tf.math.exp(-x))\n",
    "        self.loss = cross_entropy_error(tf.constant([1 - self.y.numpy(), self.y.numpy()]),\n",
    "                                        tf.constant([1 - self.t.numpy(), self.t.numpy()], dtype='float32'))\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - tf.dtypes.cast(self.t, dtype='float32')) * dout / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    num_label = y.shape[1]\n",
    "#     t = tf.dtypes.cast(t, dtype='float')\n",
    "    if t.ndim == 1:\n",
    "        t = tf.constant(np.identity(num_label)[t.numpy()], dtype='float')\n",
    "#         t = tf.one_hot(t, num_label)\n",
    "    batch_size = y.shape[0]\n",
    "\n",
    "    return -tf.reduce_sum(tf.math.log(y)*t) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from common.np import *  # import numpy as np\n",
    "from common.util import clip_grads\n",
    "import tensorflow as tf\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            # シャッフル\n",
    "            idx = tf.random.shuffle(tf.range(data_size)).numpy()\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "                # 勾配を求め、パラメータを更新\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                optimizer.update(model.params, model.grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "                # 評価\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| epoch %d |  iter %d / %d | time %d[s] | loss %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = np.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label='train')\n",
    "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494.29025864601135\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# ハイパーパラメータの設定\n",
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 200\n",
    "max_epoch = 10\n",
    "\n",
    "# データの読み込み\n",
    "# text = 'You say goodbye and I say hello.'\n",
    "# corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus = tf.constant(corpus)\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "\n",
    "# モデルなどの生成\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "# model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 46478 | time 0[s] | loss nan\n",
      "| epoch 1 |  iter 21 / 46478 | time 3[s] | loss nan\n",
      "| epoch 1 |  iter 41 / 46478 | time 7[s] | loss nan\n",
      "| epoch 1 |  iter 61 / 46478 | time 10[s] | loss nan\n",
      "| epoch 1 |  iter 81 / 46478 | time 14[s] | loss nan\n",
      "| epoch 1 |  iter 101 / 46478 | time 17[s] | loss nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-7a76fc2839a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-242-8bee89801fb4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mloss_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/practice/python_ML/ゼロからDL自然言語/common/optimizer.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, params, grads)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mpow\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    448\u001b[0m   \"\"\"\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_pow\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6954\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   6955\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pow\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6956\u001b[0;31m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   6957\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6958\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習開始\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'ResourceVariable' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-91521da42b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_vecs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_to_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_to_word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_to_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResourceVariable' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.plot()\n",
    "\n",
    "# 後ほど利用できるように、必要なデータを保存\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'  # or 'skipgram_params.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
