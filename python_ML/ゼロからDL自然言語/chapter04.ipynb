{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "import collections\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "#         self.grads = [tf.Variable(tf.zeros_like(W))]\n",
    "        self.grads = [tf.Variable(tf.zeros_like(W))]\n",
    "        self.idx = None\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W.numpy()[idx, :]\n",
    "        return tf.Variable(out)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "#         for word_id in self.idx:\n",
    "#             self.grads[0].assign(self.grads[0] + tf.slice(dout, [word_id, 0], [1, dout.shape[1]]))\n",
    "        grads_np = np.zeros_like(self.params[0].numpy())\n",
    "        grads_np[self.idx, :] += dout.numpy()\n",
    "        self.grads[0].assign(grads_np)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, h, idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = tf.math.reduce_sum(target_W * h, axis=1)\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = tf.reshape(dout, (dout.shape[0], 1))\n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramSampler:\n",
    "    def __init__(self, corpus, power, sample_size):\n",
    "        self.sample_size = sample_size\n",
    "        self.vocab_size = None\n",
    "        self.word_p = None\n",
    "\n",
    "        self.counts = collections.Counter(corpus.numpy())\n",
    "        vocab_size = len(self.counts)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.word_p = np.zeros(vocab_size)\n",
    "        for i in range(vocab_size):\n",
    "            self.word_p[i] = self.counts[i]\n",
    "\n",
    "        self.word_p = np.power(self.word_p, power)\n",
    "        self.word_p /= np.sum(self.word_p)\n",
    "\n",
    "    def get_negative_sample(self, target):\n",
    "        batch_size = target.shape[0]\n",
    "        if not GPU:\n",
    "            negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                p = self.word_p.copy()\n",
    "                target_idx = target[i]\n",
    "                p[target_idx] = 0\n",
    "                p /= p.sum()\n",
    "                negative_sample[i, :] = np.random.choice(list(self.counts.keys()), size=self.sample_size, replace=False, p=p)\n",
    "        else:\n",
    "            # GPU(cupy）で計算するときは、速度を優先\n",
    "            # 負例にターゲットが含まれるケースがある\n",
    "            negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size),\n",
    "                                               replace=True, p=self.word_p)\n",
    "\n",
    "        return negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power=0.75, sample_size=5):\n",
    "        self.sample_size = sample_size\n",
    "        self.samplar = UnigramSampler(corpus, power, sample_size)\n",
    "        self.loss_layer = [SigmoidWithLoss() for _ in range(sample_size + 1)]\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]\n",
    "        \n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, h, target):\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.samplar.get_negative_sample(target)\n",
    "\n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = tf.ones(batch_size, dtype='int32')\n",
    "        loss = self.loss_layer[0].forward(score, correct_label)\n",
    "\n",
    "        negative_label = tf.zeros(batch_size, dtype='int32')\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:, 1]\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_layer[1 + i].forward(score, negative_label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for l0, l1 in zip(self.loss_layer, self.embed_dot_layers):\n",
    "            dscore = l0.backward(dout)\n",
    "            dh += l1.backward(dscore)\n",
    "\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 重みの初期化\n",
    "        W_in = tf.Variable(tf.random.normal((V, H), mean=0.0, stddev=0.01, dtype='float'))\n",
    "        W_out = tf.Variable(tf.random.normal((V, H), mean=0.0, stddev=0.01, dtype='float'))\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embeddingレイヤを使用\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # メンバ変数に単語の分散表現を設定\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "from common.optimizer import Adam\n",
    "from common.functions import softmax, cross_entropy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None  # sigmoidの出力\n",
    "        self.t = None  # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = 1 / (1 + tf.math.exp(-x))\n",
    "        self.loss = cross_entropy_error(tf.constant([1 - self.y.numpy(), self.y.numpy()]),\n",
    "                                        tf.constant([1 - self.t.numpy(), self.t.numpy()], dtype='float32'))\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - tf.dtypes.cast(self.t, dtype='float32')) * dout / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    num_label = y.shape[0]\n",
    "#     print(y.shape)\n",
    "    if t.ndim == 1:\n",
    "        t = tf.constant(np.identity(num_label)[t.numpy()], dtype='float')\n",
    "    batch_size = y.shape[1]\n",
    "\n",
    "    return -tf.reduce_sum(tf.math.log(y)*t) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from common.np import *  # import numpy as np\n",
    "from common.util import clip_grads\n",
    "import tensorflow as tf\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            # シャッフル\n",
    "            idx = tf.random.shuffle(tf.range(data_size)).numpy()\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "                # 勾配を求め、パラメータを更新\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                optimizer.update(model.params, model.grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "                # 評価\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| epoch %d |  iter %d / %d | time %d[s] | loss %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = np.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label='train')\n",
    "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494.97179651260376\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# ハイパーパラメータの設定\n",
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10\n",
    "\n",
    "# データの読み込み\n",
    "# text = 'You say goodbye and I say hello.'\n",
    "# corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus = tf.constant(corpus)\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "\n",
    "# モデルなどの生成\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "# model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 9295 | time 0[s] | loss 4.16\n",
      "| epoch 1 |  iter 21 / 9295 | time 4[s] | loss 4.16\n",
      "| epoch 1 |  iter 41 / 9295 | time 8[s] | loss 4.13\n",
      "| epoch 1 |  iter 61 / 9295 | time 12[s] | loss 3.99\n",
      "| epoch 1 |  iter 81 / 9295 | time 17[s] | loss 3.89\n",
      "| epoch 1 |  iter 101 / 9295 | time 21[s] | loss 3.89\n",
      "| epoch 1 |  iter 121 / 9295 | time 25[s] | loss 3.82\n",
      "| epoch 1 |  iter 141 / 9295 | time 29[s] | loss 3.80\n",
      "| epoch 1 |  iter 161 / 9295 | time 33[s] | loss 3.78\n",
      "| epoch 1 |  iter 181 / 9295 | time 38[s] | loss 3.76\n",
      "| epoch 1 |  iter 201 / 9295 | time 42[s] | loss 3.76\n",
      "| epoch 1 |  iter 221 / 9295 | time 46[s] | loss 3.74\n",
      "| epoch 1 |  iter 241 / 9295 | time 50[s] | loss 3.67\n",
      "| epoch 1 |  iter 261 / 9295 | time 54[s] | loss 3.72\n",
      "| epoch 1 |  iter 281 / 9295 | time 59[s] | loss 3.72\n",
      "| epoch 1 |  iter 301 / 9295 | time 63[s] | loss 3.64\n",
      "| epoch 1 |  iter 321 / 9295 | time 67[s] | loss 3.70\n",
      "| epoch 1 |  iter 341 / 9295 | time 71[s] | loss 3.67\n",
      "| epoch 1 |  iter 361 / 9295 | time 76[s] | loss 3.71\n",
      "| epoch 1 |  iter 381 / 9295 | time 80[s] | loss 3.66\n",
      "| epoch 1 |  iter 401 / 9295 | time 84[s] | loss 3.64\n",
      "| epoch 1 |  iter 421 / 9295 | time 88[s] | loss 3.63\n",
      "| epoch 1 |  iter 441 / 9295 | time 92[s] | loss 3.67\n",
      "| epoch 1 |  iter 461 / 9295 | time 97[s] | loss 3.63\n",
      "| epoch 1 |  iter 481 / 9295 | time 101[s] | loss 3.63\n",
      "| epoch 1 |  iter 501 / 9295 | time 105[s] | loss 3.63\n",
      "| epoch 1 |  iter 521 / 9295 | time 109[s] | loss 3.62\n",
      "| epoch 1 |  iter 541 / 9295 | time 113[s] | loss 3.63\n",
      "| epoch 1 |  iter 561 / 9295 | time 117[s] | loss 3.62\n",
      "| epoch 1 |  iter 581 / 9295 | time 122[s] | loss 3.59\n",
      "| epoch 1 |  iter 601 / 9295 | time 126[s] | loss 3.64\n",
      "| epoch 1 |  iter 621 / 9295 | time 130[s] | loss 3.61\n",
      "| epoch 1 |  iter 641 / 9295 | time 134[s] | loss 3.56\n",
      "| epoch 1 |  iter 661 / 9295 | time 138[s] | loss 3.59\n",
      "| epoch 1 |  iter 681 / 9295 | time 142[s] | loss 3.62\n",
      "| epoch 1 |  iter 701 / 9295 | time 147[s] | loss 3.60\n",
      "| epoch 1 |  iter 721 / 9295 | time 151[s] | loss 3.63\n",
      "| epoch 1 |  iter 741 / 9295 | time 155[s] | loss 3.56\n",
      "| epoch 1 |  iter 761 / 9295 | time 159[s] | loss 3.60\n",
      "| epoch 1 |  iter 781 / 9295 | time 163[s] | loss 3.62\n",
      "| epoch 1 |  iter 801 / 9295 | time 168[s] | loss 3.66\n",
      "| epoch 1 |  iter 821 / 9295 | time 172[s] | loss 3.63\n",
      "| epoch 1 |  iter 841 / 9295 | time 176[s] | loss 3.62\n",
      "| epoch 1 |  iter 861 / 9295 | time 180[s] | loss 3.60\n",
      "| epoch 1 |  iter 881 / 9295 | time 184[s] | loss 3.58\n",
      "| epoch 1 |  iter 901 / 9295 | time 189[s] | loss 3.64\n",
      "| epoch 1 |  iter 921 / 9295 | time 193[s] | loss 3.54\n",
      "| epoch 1 |  iter 941 / 9295 | time 197[s] | loss 3.58\n",
      "| epoch 1 |  iter 961 / 9295 | time 201[s] | loss 3.64\n",
      "| epoch 1 |  iter 981 / 9295 | time 205[s] | loss 3.59\n",
      "| epoch 1 |  iter 1001 / 9295 | time 210[s] | loss 3.60\n",
      "| epoch 1 |  iter 1021 / 9295 | time 214[s] | loss 3.61\n",
      "| epoch 1 |  iter 1041 / 9295 | time 218[s] | loss 3.59\n",
      "| epoch 1 |  iter 1061 / 9295 | time 222[s] | loss 3.55\n",
      "| epoch 1 |  iter 1081 / 9295 | time 227[s] | loss 3.60\n",
      "| epoch 1 |  iter 1101 / 9295 | time 231[s] | loss 3.58\n",
      "| epoch 1 |  iter 1121 / 9295 | time 235[s] | loss 3.62\n",
      "| epoch 1 |  iter 1141 / 9295 | time 239[s] | loss 3.57\n",
      "| epoch 1 |  iter 1161 / 9295 | time 244[s] | loss 3.57\n",
      "| epoch 1 |  iter 1181 / 9295 | time 248[s] | loss 3.59\n",
      "| epoch 1 |  iter 1201 / 9295 | time 252[s] | loss 3.55\n",
      "| epoch 1 |  iter 1221 / 9295 | time 256[s] | loss 3.60\n",
      "| epoch 1 |  iter 1241 / 9295 | time 260[s] | loss 3.58\n",
      "| epoch 1 |  iter 1261 / 9295 | time 265[s] | loss 3.54\n",
      "| epoch 1 |  iter 1281 / 9295 | time 269[s] | loss 3.60\n",
      "| epoch 1 |  iter 1301 / 9295 | time 273[s] | loss 3.61\n",
      "| epoch 1 |  iter 1321 / 9295 | time 277[s] | loss 3.53\n",
      "| epoch 1 |  iter 1341 / 9295 | time 281[s] | loss 3.56\n",
      "| epoch 1 |  iter 1361 / 9295 | time 286[s] | loss 3.58\n",
      "| epoch 1 |  iter 1381 / 9295 | time 290[s] | loss 3.57\n",
      "| epoch 1 |  iter 1401 / 9295 | time 294[s] | loss 3.58\n",
      "| epoch 1 |  iter 1421 / 9295 | time 298[s] | loss 3.63\n",
      "| epoch 1 |  iter 1441 / 9295 | time 303[s] | loss 3.57\n",
      "| epoch 1 |  iter 1461 / 9295 | time 307[s] | loss 3.57\n",
      "| epoch 1 |  iter 1481 / 9295 | time 311[s] | loss 3.58\n",
      "| epoch 1 |  iter 1501 / 9295 | time 315[s] | loss 3.57\n",
      "| epoch 1 |  iter 1521 / 9295 | time 319[s] | loss 3.58\n",
      "| epoch 1 |  iter 1541 / 9295 | time 324[s] | loss 3.55\n",
      "| epoch 1 |  iter 1561 / 9295 | time 328[s] | loss 3.53\n",
      "| epoch 1 |  iter 1581 / 9295 | time 332[s] | loss 3.55\n",
      "| epoch 1 |  iter 1601 / 9295 | time 336[s] | loss 3.61\n",
      "| epoch 1 |  iter 1621 / 9295 | time 340[s] | loss 3.59\n",
      "| epoch 1 |  iter 1641 / 9295 | time 345[s] | loss 3.57\n",
      "| epoch 1 |  iter 1661 / 9295 | time 349[s] | loss 3.57\n",
      "| epoch 1 |  iter 1681 / 9295 | time 353[s] | loss 3.60\n",
      "| epoch 1 |  iter 1701 / 9295 | time 357[s] | loss 3.54\n",
      "| epoch 1 |  iter 1721 / 9295 | time 362[s] | loss 3.55\n",
      "| epoch 1 |  iter 1741 / 9295 | time 366[s] | loss 3.59\n",
      "| epoch 1 |  iter 1761 / 9295 | time 370[s] | loss 3.57\n",
      "| epoch 1 |  iter 1781 / 9295 | time 374[s] | loss 3.53\n",
      "| epoch 1 |  iter 1801 / 9295 | time 378[s] | loss 3.55\n",
      "| epoch 1 |  iter 1821 / 9295 | time 383[s] | loss 3.57\n",
      "| epoch 1 |  iter 1841 / 9295 | time 387[s] | loss 3.57\n",
      "| epoch 1 |  iter 1861 / 9295 | time 391[s] | loss 3.54\n",
      "| epoch 1 |  iter 1881 / 9295 | time 395[s] | loss 3.54\n",
      "| epoch 1 |  iter 1901 / 9295 | time 399[s] | loss 3.53\n",
      "| epoch 1 |  iter 1921 / 9295 | time 404[s] | loss 3.58\n",
      "| epoch 1 |  iter 1941 / 9295 | time 408[s] | loss 3.55\n",
      "| epoch 1 |  iter 1961 / 9295 | time 412[s] | loss 3.57\n",
      "| epoch 1 |  iter 1981 / 9295 | time 417[s] | loss 3.52\n",
      "| epoch 1 |  iter 2001 / 9295 | time 421[s] | loss 3.51\n",
      "| epoch 1 |  iter 2021 / 9295 | time 425[s] | loss 3.47\n",
      "| epoch 1 |  iter 2041 / 9295 | time 429[s] | loss 3.53\n",
      "| epoch 1 |  iter 2061 / 9295 | time 434[s] | loss 3.60\n",
      "| epoch 1 |  iter 2081 / 9295 | time 438[s] | loss 3.54\n",
      "| epoch 1 |  iter 2101 / 9295 | time 442[s] | loss 3.58\n",
      "| epoch 1 |  iter 2121 / 9295 | time 446[s] | loss 3.52\n",
      "| epoch 1 |  iter 2141 / 9295 | time 450[s] | loss 3.55\n",
      "| epoch 1 |  iter 2161 / 9295 | time 455[s] | loss 3.53\n",
      "| epoch 1 |  iter 2181 / 9295 | time 459[s] | loss 3.55\n",
      "| epoch 1 |  iter 2201 / 9295 | time 463[s] | loss 3.54\n",
      "| epoch 1 |  iter 2221 / 9295 | time 467[s] | loss 3.55\n",
      "| epoch 1 |  iter 2241 / 9295 | time 471[s] | loss 3.48\n",
      "| epoch 1 |  iter 2261 / 9295 | time 476[s] | loss 3.54\n",
      "| epoch 1 |  iter 2281 / 9295 | time 480[s] | loss 3.57\n",
      "| epoch 1 |  iter 2301 / 9295 | time 484[s] | loss 3.54\n",
      "| epoch 1 |  iter 2321 / 9295 | time 488[s] | loss 3.50\n",
      "| epoch 1 |  iter 2341 / 9295 | time 492[s] | loss 3.58\n",
      "| epoch 1 |  iter 2361 / 9295 | time 496[s] | loss 3.53\n",
      "| epoch 1 |  iter 2381 / 9295 | time 501[s] | loss 3.53\n",
      "| epoch 1 |  iter 2401 / 9295 | time 505[s] | loss 3.54\n",
      "| epoch 1 |  iter 2421 / 9295 | time 509[s] | loss 3.53\n",
      "| epoch 1 |  iter 2441 / 9295 | time 513[s] | loss 3.54\n",
      "| epoch 1 |  iter 2461 / 9295 | time 517[s] | loss 3.56\n",
      "| epoch 1 |  iter 2481 / 9295 | time 522[s] | loss 3.53\n",
      "| epoch 1 |  iter 2501 / 9295 | time 526[s] | loss 3.53\n",
      "| epoch 1 |  iter 2521 / 9295 | time 530[s] | loss 3.55\n",
      "| epoch 1 |  iter 2541 / 9295 | time 534[s] | loss 3.48\n",
      "| epoch 1 |  iter 2561 / 9295 | time 538[s] | loss 3.55\n",
      "| epoch 1 |  iter 2581 / 9295 | time 543[s] | loss 3.52\n",
      "| epoch 1 |  iter 2601 / 9295 | time 547[s] | loss 3.53\n",
      "| epoch 1 |  iter 2621 / 9295 | time 551[s] | loss 3.56\n",
      "| epoch 1 |  iter 2641 / 9295 | time 555[s] | loss 3.52\n",
      "| epoch 1 |  iter 2661 / 9295 | time 559[s] | loss 3.44\n",
      "| epoch 1 |  iter 2681 / 9295 | time 564[s] | loss 3.53\n",
      "| epoch 1 |  iter 2701 / 9295 | time 568[s] | loss 3.51\n",
      "| epoch 1 |  iter 2721 / 9295 | time 572[s] | loss 3.52\n",
      "| epoch 1 |  iter 2741 / 9295 | time 576[s] | loss 3.50\n",
      "| epoch 1 |  iter 2761 / 9295 | time 580[s] | loss 3.50\n",
      "| epoch 1 |  iter 2781 / 9295 | time 584[s] | loss 3.52\n",
      "| epoch 1 |  iter 2801 / 9295 | time 589[s] | loss 3.53\n",
      "| epoch 1 |  iter 2821 / 9295 | time 593[s] | loss 3.50\n",
      "| epoch 1 |  iter 2841 / 9295 | time 597[s] | loss 3.46\n",
      "| epoch 1 |  iter 2861 / 9295 | time 601[s] | loss 3.52\n",
      "| epoch 1 |  iter 2881 / 9295 | time 605[s] | loss 3.51\n",
      "| epoch 1 |  iter 2901 / 9295 | time 609[s] | loss 3.49\n",
      "| epoch 1 |  iter 2921 / 9295 | time 613[s] | loss 3.46\n",
      "| epoch 1 |  iter 2941 / 9295 | time 618[s] | loss 3.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 2961 / 9295 | time 622[s] | loss 3.51\n",
      "| epoch 1 |  iter 2981 / 9295 | time 626[s] | loss 3.50\n",
      "| epoch 1 |  iter 3001 / 9295 | time 630[s] | loss 3.47\n",
      "| epoch 1 |  iter 3021 / 9295 | time 634[s] | loss 3.49\n",
      "| epoch 1 |  iter 3041 / 9295 | time 639[s] | loss 3.54\n",
      "| epoch 1 |  iter 3061 / 9295 | time 643[s] | loss 3.53\n",
      "| epoch 1 |  iter 3081 / 9295 | time 647[s] | loss 3.51\n",
      "| epoch 1 |  iter 3101 / 9295 | time 651[s] | loss 3.52\n",
      "| epoch 1 |  iter 3121 / 9295 | time 655[s] | loss 3.47\n",
      "| epoch 1 |  iter 3141 / 9295 | time 659[s] | loss 3.51\n",
      "| epoch 1 |  iter 3161 / 9295 | time 664[s] | loss 3.49\n",
      "| epoch 1 |  iter 3181 / 9295 | time 668[s] | loss 3.47\n",
      "| epoch 1 |  iter 3201 / 9295 | time 672[s] | loss 3.46\n",
      "| epoch 1 |  iter 3221 / 9295 | time 676[s] | loss 3.49\n",
      "| epoch 1 |  iter 3241 / 9295 | time 680[s] | loss 3.48\n",
      "| epoch 1 |  iter 3261 / 9295 | time 685[s] | loss 3.41\n",
      "| epoch 1 |  iter 3281 / 9295 | time 689[s] | loss 3.50\n",
      "| epoch 1 |  iter 3301 / 9295 | time 693[s] | loss 3.48\n",
      "| epoch 1 |  iter 3321 / 9295 | time 697[s] | loss 3.54\n",
      "| epoch 1 |  iter 3341 / 9295 | time 701[s] | loss 3.50\n",
      "| epoch 1 |  iter 3361 / 9295 | time 706[s] | loss 3.47\n",
      "| epoch 1 |  iter 3381 / 9295 | time 710[s] | loss 3.53\n",
      "| epoch 1 |  iter 3401 / 9295 | time 714[s] | loss 3.49\n",
      "| epoch 1 |  iter 3421 / 9295 | time 718[s] | loss 3.47\n",
      "| epoch 1 |  iter 3441 / 9295 | time 722[s] | loss 3.41\n",
      "| epoch 1 |  iter 3461 / 9295 | time 727[s] | loss 3.43\n",
      "| epoch 1 |  iter 3481 / 9295 | time 731[s] | loss 3.44\n",
      "| epoch 1 |  iter 3501 / 9295 | time 735[s] | loss 3.50\n",
      "| epoch 1 |  iter 3521 / 9295 | time 739[s] | loss 3.50\n",
      "| epoch 1 |  iter 3541 / 9295 | time 743[s] | loss 3.43\n",
      "| epoch 1 |  iter 3561 / 9295 | time 748[s] | loss 3.47\n",
      "| epoch 1 |  iter 3581 / 9295 | time 752[s] | loss 3.46\n",
      "| epoch 1 |  iter 3601 / 9295 | time 756[s] | loss 3.47\n",
      "| epoch 1 |  iter 3621 / 9295 | time 760[s] | loss 3.46\n",
      "| epoch 1 |  iter 3641 / 9295 | time 764[s] | loss 3.48\n",
      "| epoch 1 |  iter 3661 / 9295 | time 768[s] | loss 3.48\n",
      "| epoch 1 |  iter 3681 / 9295 | time 773[s] | loss 3.46\n",
      "| epoch 1 |  iter 3701 / 9295 | time 777[s] | loss 3.50\n",
      "| epoch 1 |  iter 3721 / 9295 | time 781[s] | loss 3.48\n",
      "| epoch 1 |  iter 3741 / 9295 | time 785[s] | loss 3.48\n",
      "| epoch 1 |  iter 3761 / 9295 | time 789[s] | loss 3.46\n",
      "| epoch 1 |  iter 3781 / 9295 | time 793[s] | loss 3.46\n",
      "| epoch 1 |  iter 3801 / 9295 | time 798[s] | loss 3.45\n",
      "| epoch 1 |  iter 3821 / 9295 | time 802[s] | loss 3.49\n",
      "| epoch 1 |  iter 3841 / 9295 | time 806[s] | loss 3.39\n",
      "| epoch 1 |  iter 3861 / 9295 | time 810[s] | loss 3.49\n",
      "| epoch 1 |  iter 3881 / 9295 | time 814[s] | loss 3.45\n",
      "| epoch 1 |  iter 3901 / 9295 | time 818[s] | loss 3.36\n",
      "| epoch 1 |  iter 3921 / 9295 | time 823[s] | loss 3.46\n",
      "| epoch 1 |  iter 3941 / 9295 | time 827[s] | loss 3.47\n",
      "| epoch 1 |  iter 3961 / 9295 | time 831[s] | loss 3.45\n",
      "| epoch 1 |  iter 3981 / 9295 | time 835[s] | loss 3.48\n",
      "| epoch 1 |  iter 4001 / 9295 | time 839[s] | loss 3.48\n",
      "| epoch 1 |  iter 4021 / 9295 | time 843[s] | loss 3.49\n",
      "| epoch 1 |  iter 4041 / 9295 | time 848[s] | loss 3.49\n",
      "| epoch 1 |  iter 4061 / 9295 | time 852[s] | loss 3.42\n",
      "| epoch 1 |  iter 4081 / 9295 | time 856[s] | loss 3.42\n",
      "| epoch 1 |  iter 4101 / 9295 | time 860[s] | loss 3.51\n",
      "| epoch 1 |  iter 4121 / 9295 | time 864[s] | loss 3.46\n",
      "| epoch 1 |  iter 4141 / 9295 | time 868[s] | loss 3.48\n",
      "| epoch 1 |  iter 4161 / 9295 | time 872[s] | loss 3.44\n",
      "| epoch 1 |  iter 4181 / 9295 | time 877[s] | loss 3.51\n",
      "| epoch 1 |  iter 4201 / 9295 | time 881[s] | loss 3.42\n",
      "| epoch 1 |  iter 4221 / 9295 | time 885[s] | loss 3.49\n",
      "| epoch 1 |  iter 4241 / 9295 | time 889[s] | loss 3.48\n",
      "| epoch 1 |  iter 4261 / 9295 | time 893[s] | loss 3.44\n",
      "| epoch 1 |  iter 4281 / 9295 | time 897[s] | loss 3.46\n",
      "| epoch 1 |  iter 4301 / 9295 | time 901[s] | loss 3.45\n",
      "| epoch 1 |  iter 4321 / 9295 | time 906[s] | loss 3.44\n",
      "| epoch 1 |  iter 4341 / 9295 | time 910[s] | loss 3.46\n",
      "| epoch 1 |  iter 4361 / 9295 | time 914[s] | loss 3.43\n",
      "| epoch 1 |  iter 4381 / 9295 | time 918[s] | loss 3.46\n",
      "| epoch 1 |  iter 4401 / 9295 | time 922[s] | loss 3.49\n",
      "| epoch 1 |  iter 4421 / 9295 | time 926[s] | loss 3.45\n",
      "| epoch 1 |  iter 4441 / 9295 | time 931[s] | loss 3.44\n",
      "| epoch 1 |  iter 4461 / 9295 | time 935[s] | loss 3.48\n",
      "| epoch 1 |  iter 4481 / 9295 | time 939[s] | loss 3.49\n",
      "| epoch 1 |  iter 4501 / 9295 | time 943[s] | loss 3.50\n",
      "| epoch 1 |  iter 4521 / 9295 | time 947[s] | loss 3.48\n",
      "| epoch 1 |  iter 4541 / 9295 | time 952[s] | loss 3.45\n",
      "| epoch 1 |  iter 4561 / 9295 | time 956[s] | loss 3.47\n",
      "| epoch 1 |  iter 4581 / 9295 | time 960[s] | loss 3.48\n",
      "| epoch 1 |  iter 4601 / 9295 | time 964[s] | loss 3.48\n",
      "| epoch 1 |  iter 4621 / 9295 | time 968[s] | loss 3.40\n",
      "| epoch 1 |  iter 4641 / 9295 | time 972[s] | loss 3.45\n",
      "| epoch 1 |  iter 4661 / 9295 | time 977[s] | loss 3.43\n",
      "| epoch 1 |  iter 4681 / 9295 | time 981[s] | loss 3.49\n",
      "| epoch 1 |  iter 4701 / 9295 | time 985[s] | loss 3.45\n",
      "| epoch 1 |  iter 4721 / 9295 | time 989[s] | loss 3.44\n",
      "| epoch 1 |  iter 4741 / 9295 | time 993[s] | loss 3.44\n",
      "| epoch 1 |  iter 4761 / 9295 | time 997[s] | loss 3.47\n",
      "| epoch 1 |  iter 4781 / 9295 | time 1002[s] | loss 3.44\n",
      "| epoch 1 |  iter 4801 / 9295 | time 1006[s] | loss 3.45\n",
      "| epoch 1 |  iter 4821 / 9295 | time 1010[s] | loss 3.43\n",
      "| epoch 1 |  iter 4841 / 9295 | time 1014[s] | loss 3.43\n",
      "| epoch 1 |  iter 4861 / 9295 | time 1018[s] | loss 3.43\n",
      "| epoch 1 |  iter 4881 / 9295 | time 1022[s] | loss 3.47\n",
      "| epoch 1 |  iter 4901 / 9295 | time 1027[s] | loss 3.46\n",
      "| epoch 1 |  iter 4921 / 9295 | time 1031[s] | loss 3.45\n",
      "| epoch 1 |  iter 4941 / 9295 | time 1035[s] | loss 3.44\n",
      "| epoch 1 |  iter 4961 / 9295 | time 1039[s] | loss 3.45\n",
      "| epoch 1 |  iter 4981 / 9295 | time 1043[s] | loss 3.40\n",
      "| epoch 1 |  iter 5001 / 9295 | time 1047[s] | loss 3.48\n",
      "| epoch 1 |  iter 5021 / 9295 | time 1051[s] | loss 3.41\n",
      "| epoch 1 |  iter 5041 / 9295 | time 1056[s] | loss 3.42\n",
      "| epoch 1 |  iter 5061 / 9295 | time 1060[s] | loss 3.44\n",
      "| epoch 1 |  iter 5081 / 9295 | time 1064[s] | loss 3.43\n",
      "| epoch 1 |  iter 5101 / 9295 | time 1068[s] | loss 3.39\n",
      "| epoch 1 |  iter 5121 / 9295 | time 1072[s] | loss 3.41\n",
      "| epoch 1 |  iter 5141 / 9295 | time 1076[s] | loss 3.40\n",
      "| epoch 1 |  iter 5161 / 9295 | time 1081[s] | loss 3.45\n",
      "| epoch 1 |  iter 5181 / 9295 | time 1085[s] | loss 3.38\n",
      "| epoch 1 |  iter 5201 / 9295 | time 1089[s] | loss 3.43\n",
      "| epoch 1 |  iter 5221 / 9295 | time 1093[s] | loss 3.44\n",
      "| epoch 1 |  iter 5241 / 9295 | time 1097[s] | loss 3.39\n",
      "| epoch 1 |  iter 5261 / 9295 | time 1102[s] | loss 3.42\n",
      "| epoch 1 |  iter 5281 / 9295 | time 1106[s] | loss 3.42\n",
      "| epoch 1 |  iter 5301 / 9295 | time 1110[s] | loss 3.43\n",
      "| epoch 1 |  iter 5321 / 9295 | time 1114[s] | loss 3.45\n",
      "| epoch 1 |  iter 5341 / 9295 | time 1118[s] | loss 3.42\n",
      "| epoch 1 |  iter 5361 / 9295 | time 1122[s] | loss 3.39\n",
      "| epoch 1 |  iter 5381 / 9295 | time 1127[s] | loss 3.41\n",
      "| epoch 1 |  iter 5401 / 9295 | time 1131[s] | loss 3.45\n",
      "| epoch 1 |  iter 5421 / 9295 | time 1135[s] | loss 3.41\n",
      "| epoch 1 |  iter 5441 / 9295 | time 1139[s] | loss 3.40\n",
      "| epoch 1 |  iter 5461 / 9295 | time 1143[s] | loss 3.44\n",
      "| epoch 1 |  iter 5481 / 9295 | time 1147[s] | loss 3.44\n",
      "| epoch 1 |  iter 5501 / 9295 | time 1152[s] | loss 3.38\n",
      "| epoch 1 |  iter 5521 / 9295 | time 1156[s] | loss 3.46\n",
      "| epoch 1 |  iter 5541 / 9295 | time 1160[s] | loss 3.43\n",
      "| epoch 1 |  iter 5561 / 9295 | time 1164[s] | loss 3.46\n",
      "| epoch 1 |  iter 5581 / 9295 | time 1168[s] | loss 3.43\n",
      "| epoch 1 |  iter 5601 / 9295 | time 1173[s] | loss 3.42\n",
      "| epoch 1 |  iter 5621 / 9295 | time 1177[s] | loss 3.42\n",
      "| epoch 1 |  iter 5641 / 9295 | time 1181[s] | loss 3.42\n",
      "| epoch 1 |  iter 5661 / 9295 | time 1185[s] | loss 3.41\n",
      "| epoch 1 |  iter 5681 / 9295 | time 1189[s] | loss 3.40\n",
      "| epoch 1 |  iter 5701 / 9295 | time 1194[s] | loss 3.40\n",
      "| epoch 1 |  iter 5721 / 9295 | time 1198[s] | loss 3.42\n",
      "| epoch 1 |  iter 5741 / 9295 | time 1202[s] | loss 3.38\n",
      "| epoch 1 |  iter 5761 / 9295 | time 1206[s] | loss 3.43\n",
      "| epoch 1 |  iter 5781 / 9295 | time 1210[s] | loss 3.42\n",
      "| epoch 1 |  iter 5801 / 9295 | time 1215[s] | loss 3.41\n",
      "| epoch 1 |  iter 5821 / 9295 | time 1219[s] | loss 3.41\n",
      "| epoch 1 |  iter 5841 / 9295 | time 1223[s] | loss 3.42\n",
      "| epoch 1 |  iter 5861 / 9295 | time 1227[s] | loss 3.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 5881 / 9295 | time 1231[s] | loss 3.43\n",
      "| epoch 1 |  iter 5901 / 9295 | time 1236[s] | loss 3.44\n",
      "| epoch 1 |  iter 5921 / 9295 | time 1240[s] | loss 3.46\n",
      "| epoch 1 |  iter 5941 / 9295 | time 1244[s] | loss 3.40\n",
      "| epoch 1 |  iter 5961 / 9295 | time 1248[s] | loss 3.34\n",
      "| epoch 1 |  iter 5981 / 9295 | time 1252[s] | loss 3.36\n",
      "| epoch 1 |  iter 6001 / 9295 | time 1257[s] | loss 3.42\n",
      "| epoch 1 |  iter 6021 / 9295 | time 1261[s] | loss 3.39\n",
      "| epoch 1 |  iter 6041 / 9295 | time 1265[s] | loss 3.41\n",
      "| epoch 1 |  iter 6061 / 9295 | time 1269[s] | loss 3.44\n",
      "| epoch 1 |  iter 6081 / 9295 | time 1273[s] | loss 3.44\n",
      "| epoch 1 |  iter 6101 / 9295 | time 1278[s] | loss 3.43\n",
      "| epoch 1 |  iter 6121 / 9295 | time 1282[s] | loss 3.44\n",
      "| epoch 1 |  iter 6141 / 9295 | time 1286[s] | loss 3.44\n",
      "| epoch 1 |  iter 6161 / 9295 | time 1290[s] | loss 3.41\n",
      "| epoch 1 |  iter 6181 / 9295 | time 1294[s] | loss 3.38\n",
      "| epoch 1 |  iter 6201 / 9295 | time 1299[s] | loss 3.40\n",
      "| epoch 1 |  iter 6221 / 9295 | time 1303[s] | loss 3.37\n",
      "| epoch 1 |  iter 6241 / 9295 | time 1307[s] | loss 3.40\n",
      "| epoch 1 |  iter 6261 / 9295 | time 1311[s] | loss 3.40\n",
      "| epoch 1 |  iter 6281 / 9295 | time 1315[s] | loss 3.44\n",
      "| epoch 1 |  iter 6301 / 9295 | time 1320[s] | loss 3.36\n",
      "| epoch 1 |  iter 6321 / 9295 | time 1324[s] | loss 3.43\n",
      "| epoch 1 |  iter 6341 / 9295 | time 1328[s] | loss 3.41\n",
      "| epoch 1 |  iter 6361 / 9295 | time 1332[s] | loss 3.42\n",
      "| epoch 1 |  iter 6381 / 9295 | time 1336[s] | loss 3.41\n",
      "| epoch 1 |  iter 6401 / 9295 | time 1341[s] | loss 3.42\n",
      "| epoch 1 |  iter 6421 / 9295 | time 1345[s] | loss 3.42\n",
      "| epoch 1 |  iter 6441 / 9295 | time 1349[s] | loss 3.44\n",
      "| epoch 1 |  iter 6461 / 9295 | time 1353[s] | loss 3.40\n",
      "| epoch 1 |  iter 6481 / 9295 | time 1357[s] | loss 3.41\n",
      "| epoch 1 |  iter 6501 / 9295 | time 1362[s] | loss 3.38\n",
      "| epoch 1 |  iter 6521 / 9295 | time 1366[s] | loss 3.39\n",
      "| epoch 1 |  iter 6541 / 9295 | time 1370[s] | loss 3.34\n",
      "| epoch 1 |  iter 6561 / 9295 | time 1374[s] | loss 3.39\n",
      "| epoch 1 |  iter 6581 / 9295 | time 1378[s] | loss 3.34\n",
      "| epoch 1 |  iter 6601 / 9295 | time 1382[s] | loss 3.43\n",
      "| epoch 1 |  iter 6621 / 9295 | time 1387[s] | loss 3.44\n",
      "| epoch 1 |  iter 6641 / 9295 | time 1391[s] | loss 3.37\n",
      "| epoch 1 |  iter 6661 / 9295 | time 1395[s] | loss 3.37\n",
      "| epoch 1 |  iter 6681 / 9295 | time 1399[s] | loss 3.37\n",
      "| epoch 1 |  iter 6701 / 9295 | time 1403[s] | loss 3.35\n",
      "| epoch 1 |  iter 6721 / 9295 | time 1408[s] | loss 3.40\n",
      "| epoch 1 |  iter 6741 / 9295 | time 1412[s] | loss 3.38\n",
      "| epoch 1 |  iter 6761 / 9295 | time 1416[s] | loss 3.36\n",
      "| epoch 1 |  iter 6781 / 9295 | time 1420[s] | loss 3.40\n",
      "| epoch 1 |  iter 6801 / 9295 | time 1424[s] | loss 3.48\n",
      "| epoch 1 |  iter 6821 / 9295 | time 1429[s] | loss 3.41\n",
      "| epoch 1 |  iter 6841 / 9295 | time 1433[s] | loss 3.41\n",
      "| epoch 1 |  iter 6861 / 9295 | time 1437[s] | loss 3.40\n",
      "| epoch 1 |  iter 6881 / 9295 | time 1441[s] | loss 3.37\n",
      "| epoch 1 |  iter 6901 / 9295 | time 1445[s] | loss 3.42\n",
      "| epoch 1 |  iter 6921 / 9295 | time 1450[s] | loss 3.39\n",
      "| epoch 1 |  iter 6941 / 9295 | time 1454[s] | loss 3.42\n",
      "| epoch 1 |  iter 6961 / 9295 | time 1458[s] | loss 3.34\n",
      "| epoch 1 |  iter 6981 / 9295 | time 1462[s] | loss 3.38\n",
      "| epoch 1 |  iter 7001 / 9295 | time 1466[s] | loss 3.43\n",
      "| epoch 1 |  iter 7021 / 9295 | time 1470[s] | loss 3.39\n",
      "| epoch 1 |  iter 7041 / 9295 | time 1475[s] | loss 3.35\n",
      "| epoch 1 |  iter 7061 / 9295 | time 1479[s] | loss 3.40\n",
      "| epoch 1 |  iter 7081 / 9295 | time 1483[s] | loss 3.36\n",
      "| epoch 1 |  iter 7101 / 9295 | time 1487[s] | loss 3.44\n",
      "| epoch 1 |  iter 7121 / 9295 | time 1491[s] | loss 3.40\n",
      "| epoch 1 |  iter 7141 / 9295 | time 1496[s] | loss 3.41\n",
      "| epoch 1 |  iter 7161 / 9295 | time 1500[s] | loss 3.38\n",
      "| epoch 1 |  iter 7181 / 9295 | time 1504[s] | loss 3.35\n",
      "| epoch 1 |  iter 7201 / 9295 | time 1508[s] | loss 3.37\n",
      "| epoch 1 |  iter 7221 / 9295 | time 1512[s] | loss 3.35\n",
      "| epoch 1 |  iter 7241 / 9295 | time 1517[s] | loss 3.31\n",
      "| epoch 1 |  iter 7261 / 9295 | time 1521[s] | loss 3.37\n",
      "| epoch 1 |  iter 7281 / 9295 | time 1525[s] | loss 3.33\n",
      "| epoch 1 |  iter 7301 / 9295 | time 1529[s] | loss 3.35\n",
      "| epoch 1 |  iter 7321 / 9295 | time 1533[s] | loss 3.34\n",
      "| epoch 1 |  iter 7341 / 9295 | time 1537[s] | loss 3.38\n",
      "| epoch 1 |  iter 7361 / 9295 | time 1542[s] | loss 3.34\n",
      "| epoch 1 |  iter 7381 / 9295 | time 1546[s] | loss 3.33\n",
      "| epoch 1 |  iter 7401 / 9295 | time 1550[s] | loss 3.41\n",
      "| epoch 1 |  iter 7421 / 9295 | time 1554[s] | loss 3.36\n",
      "| epoch 1 |  iter 7441 / 9295 | time 1558[s] | loss 3.40\n",
      "| epoch 1 |  iter 7461 / 9295 | time 1563[s] | loss 3.35\n",
      "| epoch 1 |  iter 7481 / 9295 | time 1567[s] | loss 3.42\n",
      "| epoch 1 |  iter 7501 / 9295 | time 1571[s] | loss 3.34\n",
      "| epoch 1 |  iter 7521 / 9295 | time 1575[s] | loss 3.43\n",
      "| epoch 1 |  iter 7541 / 9295 | time 1579[s] | loss 3.37\n",
      "| epoch 1 |  iter 7561 / 9295 | time 1584[s] | loss 3.32\n",
      "| epoch 1 |  iter 7581 / 9295 | time 1588[s] | loss 3.32\n",
      "| epoch 1 |  iter 7601 / 9295 | time 1592[s] | loss 3.31\n",
      "| epoch 1 |  iter 7621 / 9295 | time 1596[s] | loss 3.32\n",
      "| epoch 1 |  iter 7641 / 9295 | time 1600[s] | loss 3.33\n",
      "| epoch 1 |  iter 7661 / 9295 | time 1605[s] | loss 3.31\n",
      "| epoch 1 |  iter 7681 / 9295 | time 1609[s] | loss 3.38\n",
      "| epoch 1 |  iter 7701 / 9295 | time 1613[s] | loss 3.33\n",
      "| epoch 1 |  iter 7721 / 9295 | time 1617[s] | loss 3.36\n",
      "| epoch 1 |  iter 7741 / 9295 | time 1621[s] | loss 3.35\n",
      "| epoch 1 |  iter 7761 / 9295 | time 1626[s] | loss 3.37\n",
      "| epoch 1 |  iter 7781 / 9295 | time 1630[s] | loss 3.37\n",
      "| epoch 1 |  iter 7801 / 9295 | time 1634[s] | loss 3.37\n",
      "| epoch 1 |  iter 7821 / 9295 | time 1638[s] | loss 3.38\n",
      "| epoch 1 |  iter 7841 / 9295 | time 1642[s] | loss 3.43\n",
      "| epoch 1 |  iter 7861 / 9295 | time 1646[s] | loss 3.39\n",
      "| epoch 1 |  iter 7881 / 9295 | time 1651[s] | loss 3.32\n",
      "| epoch 1 |  iter 7901 / 9295 | time 1655[s] | loss 3.40\n",
      "| epoch 1 |  iter 7921 / 9295 | time 1659[s] | loss 3.34\n",
      "| epoch 1 |  iter 7941 / 9295 | time 1663[s] | loss 3.39\n",
      "| epoch 1 |  iter 7961 / 9295 | time 1668[s] | loss 3.35\n",
      "| epoch 1 |  iter 7981 / 9295 | time 1672[s] | loss 3.34\n",
      "| epoch 1 |  iter 8001 / 9295 | time 1676[s] | loss 3.36\n",
      "| epoch 1 |  iter 8021 / 9295 | time 1680[s] | loss 3.41\n",
      "| epoch 1 |  iter 8041 / 9295 | time 1684[s] | loss 3.31\n",
      "| epoch 1 |  iter 8061 / 9295 | time 1689[s] | loss 3.32\n",
      "| epoch 1 |  iter 8081 / 9295 | time 1693[s] | loss 3.38\n",
      "| epoch 1 |  iter 8101 / 9295 | time 1697[s] | loss 3.35\n",
      "| epoch 1 |  iter 8121 / 9295 | time 1701[s] | loss 3.36\n",
      "| epoch 1 |  iter 8141 / 9295 | time 1705[s] | loss 3.39\n",
      "| epoch 1 |  iter 8161 / 9295 | time 1710[s] | loss 3.35\n",
      "| epoch 1 |  iter 8181 / 9295 | time 1714[s] | loss 3.35\n",
      "| epoch 1 |  iter 8201 / 9295 | time 1718[s] | loss 3.38\n",
      "| epoch 1 |  iter 8221 / 9295 | time 1722[s] | loss 3.34\n",
      "| epoch 1 |  iter 8241 / 9295 | time 1726[s] | loss 3.39\n",
      "| epoch 1 |  iter 8261 / 9295 | time 1730[s] | loss 3.32\n",
      "| epoch 1 |  iter 8281 / 9295 | time 1735[s] | loss 3.32\n",
      "| epoch 1 |  iter 8301 / 9295 | time 1739[s] | loss 3.33\n",
      "| epoch 1 |  iter 8321 / 9295 | time 1743[s] | loss 3.34\n",
      "| epoch 1 |  iter 8341 / 9295 | time 1747[s] | loss 3.32\n",
      "| epoch 1 |  iter 8361 / 9295 | time 1751[s] | loss 3.34\n",
      "| epoch 1 |  iter 8381 / 9295 | time 1755[s] | loss 3.37\n",
      "| epoch 1 |  iter 8401 / 9295 | time 1760[s] | loss 3.39\n",
      "| epoch 1 |  iter 8421 / 9295 | time 1764[s] | loss 3.38\n",
      "| epoch 1 |  iter 8441 / 9295 | time 1768[s] | loss 3.32\n",
      "| epoch 1 |  iter 8461 / 9295 | time 1772[s] | loss 3.32\n",
      "| epoch 1 |  iter 8481 / 9295 | time 1776[s] | loss 3.35\n",
      "| epoch 1 |  iter 8501 / 9295 | time 1781[s] | loss 3.32\n",
      "| epoch 1 |  iter 8521 / 9295 | time 1785[s] | loss 3.41\n",
      "| epoch 1 |  iter 8541 / 9295 | time 1790[s] | loss 3.34\n",
      "| epoch 1 |  iter 8561 / 9295 | time 1794[s] | loss 3.36\n",
      "| epoch 1 |  iter 8581 / 9295 | time 1798[s] | loss 3.33\n",
      "| epoch 1 |  iter 8601 / 9295 | time 1803[s] | loss 3.35\n",
      "| epoch 1 |  iter 8621 / 9295 | time 1807[s] | loss 3.37\n",
      "| epoch 1 |  iter 8641 / 9295 | time 1811[s] | loss 3.31\n",
      "| epoch 1 |  iter 8661 / 9295 | time 1816[s] | loss 3.29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-7a76fc2839a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-8bee89801fb4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-bd011ed418cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, contexts, target)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-0708de910095>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         shape=None):\n\u001b[1;32m    236\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2549\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m       shape=shape)\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    462\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m           shape=shape)\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    616\u001b[0m               \u001b[0mshared_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m               graph_mode=self._in_graph_mode)\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         if (self._in_graph_mode and initial_value is not None and\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36meager_safe_variable_handle\u001b[0;34m(initial_value, shape, shared_name, name, graph_mode)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   return variable_handle_from_shape_and_dtype(\n\u001b[0;32m--> 225\u001b[0;31m       shape, dtype, shared_name, name, graph_mode, initial_value)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_handle_from_shape_and_dtype\u001b[0;34m(shape, dtype, shared_name, name, graph_mode, extra_handle_data)\u001b[0m\n\u001b[1;32m    163\u001b[0m                                                   \u001b[0mshared_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                                                   \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                                                   container=container)\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;31m# Tensor._handle_data contains information for the shape-inference code to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mvar_handle_op\u001b[0;34m(dtype, shape, container, shared_name, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   1429\u001b[0m         \u001b[0;34m\"VarHandleOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                        shared_name=shared_name, name=name)\n\u001b[0m\u001b[1;32m   1431\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    699\u001b[0m           \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetInParent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m           \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MakeStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHasField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allowed_values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowed_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習開始\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09515672,  0.19175366, -0.00521946,  0.12827146,  0.08398496,\n",
       "       -0.00368624, -0.06837357, -0.3067216 ,  0.0280181 ,  0.05105996,\n",
       "        0.11365145,  0.27883512, -0.01074899,  0.10626857, -0.12060522,\n",
       "        0.02509419,  0.1287024 ,  0.12075949, -0.1669756 ,  0.11371189,\n",
       "        0.09995188, -0.08504936, -0.24357823, -0.312678  , -0.2535549 ,\n",
       "        0.04039108,  0.21945576,  0.13762042, -0.25966632,  0.15046394,\n",
       "        0.06152108,  0.22142877, -0.13093215,  0.08544157,  0.22669505,\n",
       "        0.19041117,  0.00549628,  0.20289133,  0.06710194,  0.28464207,\n",
       "        0.14027312,  0.07994741, -0.12984921,  0.07886861, -0.09659693,\n",
       "       -0.01715551, -0.11354088, -0.1681149 ,  0.10218746,  0.12850848,\n",
       "       -0.09125027,  0.04881507,  0.36869717, -0.27636907,  0.13506028,\n",
       "       -0.09355669, -0.06014849,  0.09114479, -0.02712603, -0.0341729 ,\n",
       "        0.02463563, -0.0210257 , -0.06536174, -0.12065198, -0.08622468,\n",
       "       -0.05491001, -0.1105256 , -0.08281759,  0.12351169,  0.22535118,\n",
       "        0.12662189, -0.09805426, -0.0082526 ,  0.19225763,  0.2350949 ,\n",
       "       -0.04203294, -0.2704833 ,  0.06856865,  0.101001  ,  0.17272504,\n",
       "        0.07118705, -0.09364091,  0.26976478,  0.17408706,  0.16738424,\n",
       "        0.09994803, -0.02174992,  0.05998918,  0.00319025,  0.05192674,\n",
       "       -0.1511754 ,  0.01985325,  0.05873266, -0.00333938,  0.13652682,\n",
       "       -0.14202984,  0.07547934, -0.23152953,  0.14246044, -0.03991434,\n",
       "       -0.1553392 , -0.10811082, -0.05102895,  0.00922194, -0.08744676,\n",
       "       -0.09668344,  0.05738055, -0.08506057, -0.02525255,  0.07193796,\n",
       "        0.06964927, -0.0953506 , -0.0566611 ,  0.02648867, -0.00618704,\n",
       "        0.12040734, -0.15994486, -0.05772073,  0.36428913,  0.00592817,\n",
       "        0.12539312, -0.24153794, -0.00375201, -0.09576199, -0.14569435,\n",
       "       -0.15245113,  0.00401832, -0.19952857, -0.00737602, -0.0119393 ,\n",
       "       -0.09880804, -0.06432778, -0.11376987,  0.05268906, -0.05222875,\n",
       "       -0.1331123 ,  0.02424929,  0.11265127, -0.08153647,  0.03747164,\n",
       "        0.18074907, -0.02443058, -0.06993759, -0.23828356,  0.40097025,\n",
       "       -0.06272423,  0.0971101 ,  0.05566559,  0.00122808, -0.08269931,\n",
       "       -0.08625393, -0.03961242,  0.01338355, -0.08451089,  0.19072095,\n",
       "        0.09572106,  0.11569002,  0.09409785, -0.16278052,  0.05522675,\n",
       "        0.03904704, -0.11293837,  0.10317763, -0.20926487, -0.03971404,\n",
       "        0.05426274, -0.2834121 ,  0.20869264, -0.0017466 , -0.3536248 ,\n",
       "        0.1922762 ,  0.00416985, -0.18870893, -0.00804557,  0.192824  ,\n",
       "       -0.08747473,  0.05586015,  0.24774513, -0.1302563 ,  0.00591925,\n",
       "       -0.16614501, -0.04317378, -0.18344752,  0.09816999, -0.09469321,\n",
       "       -0.13922824, -0.07241331,  0.17307709, -0.04316586,  0.1584329 ,\n",
       "       -0.22041008, -0.11470482,  0.07483289, -0.09970839, -0.05715718,\n",
       "       -0.2332919 ,  0.06627766, -0.05613208,  0.11328625, -0.12941821],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs.numpy()[word_to_id['and']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "trainer.plot()\n",
    "\n",
    "# 後ほど利用できるように、必要なデータを保存\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'  # or 'skipgram_params.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " stepping: 0.9746652245521545\n",
      " content: 0.9620257616043091\n",
      " secure: 0.9616966247558594\n",
      " equaling: 0.9602655172348022\n",
      " spoken: 0.9585345983505249\n",
      "\n",
      "[query] year\n",
      " mo.: 0.9569869637489319\n",
      " rather: 0.9472987651824951\n",
      " thousand: 0.9407504200935364\n",
      " more: 0.9383667707443237\n",
      " less: 0.915993332862854\n",
      "\n",
      "[query] cat\n",
      " comfortable: 0.9853246808052063\n",
      " nobody: 0.9665930867195129\n",
      " reforms: 0.9578949213027954\n",
      " jose: 0.9570389986038208\n",
      " relief: 0.9565960168838501\n",
      "\n",
      "[query] toyota\n",
      " laws: 0.9738577008247375\n",
      " decision: 0.9673885703086853\n",
      " stocks: 0.9613497853279114\n",
      " pc: 0.9601082801818848\n",
      " spawned: 0.9574313759803772\n"
     ]
    }
   ],
   "source": [
    "querys = ['you','year','cat','toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
